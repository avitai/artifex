{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run benchmarks on protein models and establish baseline metrics.\n",
    "\n",
    "This script applies the benchmark suite to protein models and generates\n",
    "visualization outputs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.nnx as nnx\n",
    "import jax\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from artifex.benchmarks.datasets.protein_dataset import (\n",
    "    create_synthetic_protein_dataset,\n",
    ")\n",
    "from artifex.benchmarks.suites.protein_benchmarks import ProteinBenchmarkSuite\n",
    "from artifex.generative_models.core.configuration import (\n",
    "    PointCloudNetworkConfig,\n",
    "    ProteinPointCloudConfig,\n",
    ")\n",
    "from artifex.generative_models.models.geometric.protein_point_cloud import ProteinPointCloudModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"Parse command line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Run benchmarks on protein generative models\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        type=str,\n",
    "        default=\"benchmark_results\",\n",
    "        help=\"Directory to save benchmark results\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--num_samples\",\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help=\"Number of samples to generate for evaluation\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--random_seed\",\n",
    "        type=int,\n",
    "        default=42,\n",
    "        help=\"Random seed for reproducible results\",\n",
    "    )\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_model(config, seed=42):\n",
    "    \"\"\"Create a test protein model for benchmarking.\n",
    "\n",
    "    Args:\n",
    "        config: Model configuration dict with model parameters\n",
    "        seed: Random seed\n",
    "\n",
    "    Returns:\n",
    "        Initialized protein model\n",
    "    \"\"\"\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    rngs = nnx.Rngs(params=key, dropout=key, sample=key)\n",
    "\n",
    "    # Create network config for the point cloud model\n",
    "    network_config = PointCloudNetworkConfig(\n",
    "        name=\"protein_network\",\n",
    "        hidden_dims=(config[\"embed_dim\"], config[\"embed_dim\"] * 2),\n",
    "        activation=\"gelu\",\n",
    "        embed_dim=config[\"embed_dim\"],\n",
    "        num_heads=config[\"num_heads\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        dropout_rate=config.get(\"dropout\", 0.1),\n",
    "    )\n",
    "\n",
    "    # Create ProteinPointCloudConfig with proper nested config\n",
    "    model_config = ProteinPointCloudConfig(\n",
    "        name=f\"protein_model_{config.get('model_variant', 'base')}\",\n",
    "        network=network_config,\n",
    "        num_points=config[\"num_residues\"] * config[\"num_atoms\"],\n",
    "        num_residues=config[\"num_residues\"],\n",
    "        num_atoms_per_residue=config[\"num_atoms\"],\n",
    "        backbone_indices=tuple(config[\"backbone_indices\"]),\n",
    "        use_constraints=config.get(\"use_constraints\", True),\n",
    "        dropout_rate=config.get(\"dropout\", 0.1),\n",
    "    )\n",
    "\n",
    "    # Create protein point cloud model with proper config\n",
    "    model = ProteinPointCloudModel(model_config, rngs=rngs)\n",
    "\n",
    "    # Set model name for better reporting\n",
    "    model.model_name = f\"protein_model_{config.get('model_variant', 'base')}\"\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the protein model benchmarks.\"\"\"\n",
    "    # Parse command line arguments\n",
    "    args = parse_args()\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    # Set up random seed\n",
    "    seed = args.random_seed\n",
    "\n",
    "    # Create synthetic protein dataset for testing\n",
    "    # In a real scenario, this would be a real protein dataset\n",
    "    from pathlib import Path\n",
    "\n",
    "    from flax import nnx\n",
    "\n",
    "    from artifex.generative_models.core.configuration import DataConfig\n",
    "    from artifex.generative_models.core.device_manager import DeviceManager\n",
    "\n",
    "    DeviceManager()\n",
    "    rngs = nnx.Rngs(seed)\n",
    "\n",
    "    data_config = DataConfig(\n",
    "        name=\"synthetic_protein_data\",\n",
    "        dataset_name=\"synthetic_protein\",\n",
    "        data_dir=Path(\"./protein_data\"),\n",
    "        metadata={\n",
    "            \"num_samples\": 500,\n",
    "            \"num_residues\": 10,\n",
    "            \"num_atoms\": 4,\n",
    "            \"seed\": seed,\n",
    "            \"batch_size\": 32,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_dataset = create_synthetic_protein_dataset(\n",
    "        config=data_config, rngs=rngs, data_path=\"./protein_data\"\n",
    "    )\n",
    "\n",
    "    # Create configurations for different model variants\n",
    "    model_configs = [\n",
    "        {\n",
    "            \"model_variant\": \"base\",\n",
    "            \"num_residues\": 10,\n",
    "            \"num_atoms\": 4,\n",
    "            \"backbone_indices\": [0, 1, 2, 3],\n",
    "            \"use_constraints\": True,\n",
    "            \"embed_dim\": 64,\n",
    "            \"num_layers\": 3,\n",
    "            \"num_heads\": 4,\n",
    "            \"dropout\": 0.1,\n",
    "        },\n",
    "        {\n",
    "            \"model_variant\": \"large\",\n",
    "            \"num_residues\": 10,\n",
    "            \"num_atoms\": 4,\n",
    "            \"backbone_indices\": [0, 1, 2, 3],\n",
    "            \"use_constraints\": True,\n",
    "            \"embed_dim\": 128,\n",
    "            \"num_layers\": 6,\n",
    "            \"num_heads\": 8,\n",
    "            \"dropout\": 0.1,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Initialize the benchmark suite\n",
    "    benchmark_suite = ProteinBenchmarkSuite(num_samples=args.num_samples, random_seed=seed)\n",
    "\n",
    "    # Run benchmarks for each model configuration\n",
    "    for config in model_configs:\n",
    "        print(f\"Running benchmarks for {config['model_variant']} model...\")\n",
    "\n",
    "        # Create model\n",
    "        model = create_test_model(config, seed=seed)\n",
    "\n",
    "        # Run all benchmarks\n",
    "        results = benchmark_suite.run_all(model, train_dataset)\n",
    "\n",
    "        # Print results\n",
    "        for benchmark_name, result in results.items():\n",
    "            print(f\"\\n{benchmark_name} metrics:\")\n",
    "            for metric_name, value in result.metrics.items():\n",
    "                print(f\"  {metric_name}: {value:.4f}\")\n",
    "\n",
    "            # Save results to file\n",
    "            result_path = os.path.join(\n",
    "                args.output_dir, f\"{config['model_variant']}_{benchmark_name}_results.json\"\n",
    "            )\n",
    "            result.save(result_path)\n",
    "            print(f\"Results saved to {result_path}\")\n",
    "\n",
    "    # Visualize results\n",
    "    benchmark_suite.visualize_results()\n",
    "\n",
    "    # Save visualization\n",
    "    vis_path = os.path.join(args.output_dir, \"protein_benchmark_results.png\")\n",
    "    plt.savefig(vis_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Visualization saved to {vis_path}\")\n",
    "\n",
    "    # Create a markdown summary report\n",
    "    summary_path = os.path.join(args.output_dir, \"protein_benchmark_summary.md\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        f.write(\"# Protein Model Benchmark Results\\n\\n\")\n",
    "\n",
    "        f.write(\"## Models Evaluated\\n\\n\")\n",
    "        for config in model_configs:\n",
    "            f.write(f\"- {config['model_variant']}: \")\n",
    "            f.write(f\"{config['num_layers']} layers, \")\n",
    "            f.write(f\"{config['embed_dim']} embedding dim, \")\n",
    "            f.write(f\"{config['num_heads']} attention heads\\n\")\n",
    "\n",
    "        f.write(\"\\n## Benchmark Results\\n\\n\")\n",
    "\n",
    "        for model_name in benchmark_suite.results:\n",
    "            f.write(f\"### {model_name}\\n\\n\")\n",
    "\n",
    "            for benchmark_name, result in benchmark_suite.results[model_name].items():\n",
    "                f.write(f\"#### {benchmark_name}\\n\\n\")\n",
    "                f.write(\"| Metric | Value |\\n\")\n",
    "                f.write(\"|--------|-------|\\n\")\n",
    "\n",
    "                for metric_name, value in result.metrics.items():\n",
    "                    f.write(f\"| {metric_name} | {value:.4f} |\\n\")\n",
    "\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"\\n## Visualization\\n\\n\")\n",
    "        f.write(\"![Protein Benchmark Results](protein_benchmark_results.png)\\n\")\n",
    "\n",
    "    print(f\"Summary report saved to {summary_path}\")\n",
    "    print(\"Benchmark completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
