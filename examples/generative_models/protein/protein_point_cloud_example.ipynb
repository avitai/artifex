{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Protein Point Cloud Model Example\n",
    "\n",
    "This example demonstrates the ProteinPointCloudModel, a specialized geometric model\n",
    "designed for protein structure generation and refinement. The model combines point\n",
    "cloud processing with protein-specific constraints (bond lengths, angles) to generate\n",
    "physically plausible protein structures.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand the protein point cloud representation (atoms as 3D points)\n",
    "- Learn to create and configure ProteinPointCloudModel\n",
    "- Work with backbone-only protein representations\n",
    "- Apply geometric constraints during generation\n",
    "- Evaluate model outputs with protein-specific metrics\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of protein structure (residues, atoms, backbone)\n",
    "- Familiarity with point cloud representations\n",
    "- Knowledge of Flax NNX and JAX basics\n",
    "- Understanding of generative models\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Point Cloud Representation**: Proteins are represented as sets of 3D points,\n",
    "where each point corresponds to an atom. This representation is invariant to\n",
    "rotation and translation, making it ideal for geometric modeling.\n",
    "\n",
    "**Backbone Atoms**: The protein backbone consists of N (nitrogen), CA (alpha carbon),\n",
    "C (carbon), and O (oxygen) atoms. These four atoms are present in every amino acid\n",
    "and determine the overall protein structure.\n",
    "\n",
    "**Geometric Constraints**: Physical constraints like bond lengths and angles are\n",
    "enforced during generation to ensure the output structures are chemically valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "\n",
    "from artifex.data.protein.dataset import (\n",
    "    ATOM_TYPES,\n",
    "    BACKBONE_ATOM_INDICES,\n",
    "    ProteinDataset,\n",
    ")\n",
    "from artifex.generative_models.core.configuration import (\n",
    "    PointCloudNetworkConfig,\n",
    "    ProteinConstraintConfig,\n",
    "    ProteinPointCloudConfig,\n",
    ")\n",
    "from artifex.generative_models.models.geometric.protein_point_cloud import (\n",
    "    ProteinPointCloudModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "## Setup and Initialization\n",
    "\n",
    "First, we'll set up our environment and initialize the random number generator.\n",
    "Artifex uses Flax NNX's `Rngs` class for managing random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create RNG keys\n",
    "# We need separate keys for parameters and dropout\n",
    "key = jax.random.key(42)\n",
    "key, params_key, dropout_key = jax.random.split(key, 3)\n",
    "rngs = nnx.Rngs(params=params_key, dropout=dropout_key)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the protein point cloud model example.\"\"\"\n",
    "    print(\"Creating protein point cloud model example...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #     ## Model Configuration\n",
    "    #\n",
    "    #     The ProteinPointCloudModel requires configuration that specifies:\n",
    "    #     - Model architecture (embedding dimension, layers, attention heads)\n",
    "    #     - Protein structure parameters (number of residues, atoms per residue)\n",
    "    #     - Constraint parameters (bond and angle weights)\n",
    "    #\n",
    "    #     **Important**: The model uses attention mechanisms to capture long-range\n",
    "    #     interactions between amino acids, making it suitable for modeling protein folding.\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration with protein-specific parameters\n",
    "# Create network config for point cloud processing\n",
    "network_config = PointCloudNetworkConfig(\n",
    "    name=\"protein_network\",\n",
    "    hidden_dims=(128, 128, 128, 128),  # 4 layers for hierarchical processing\n",
    "    activation=\"gelu\",\n",
    "    embed_dim=128,  # Embedding dimension for each atom\n",
    "    num_heads=4,  # Number of attention heads\n",
    "    num_layers=4,  # Number of transformer layers\n",
    "    dropout_rate=0.1,  # Dropout rate for regularization\n",
    ")\n",
    "\n",
    "# Create constraint config for structural constraints\n",
    "constraint_config = ProteinConstraintConfig(\n",
    "    bond_weight=1.0,  # Weight for bond length constraints\n",
    "    angle_weight=0.5,  # Weight for bond angle constraints\n",
    ")\n",
    "\n",
    "# Create protein point cloud config with nested configs\n",
    "# Note: backbone_indices is (0, 1, 2, 3) for the backbone-only view (N, CA, C, O)\n",
    "# BACKBONE_ATOM_INDICES from dataset.py is [0, 1, 2, 4] - indices in the FULL atom list\n",
    "config = ProteinPointCloudConfig(\n",
    "    name=\"protein_example\",\n",
    "    network=network_config,\n",
    "    num_points=128 * 4,  # num_residues * num_atoms (flattened)\n",
    "    dropout_rate=0.1,\n",
    "    # Protein-specific parameters\n",
    "    num_residues=128,  # Maximum number of residues\n",
    "    num_atoms_per_residue=4,  # Only backbone atoms (N, CA, C, O)\n",
    "    backbone_indices=(0, 1, 2, 3),  # Sequential indices for backbone-only view\n",
    "    use_constraints=True,  # Enable geometric constraints\n",
    "    constraint_config=constraint_config,\n",
    ")\n",
    "\n",
    "print(\"\\nModel configuration:\")\n",
    "print(f\"  Embedding dimension: {config.network.embed_dim}\")\n",
    "print(f\"  Number of layers: {config.network.num_layers}\")\n",
    "print(f\"  Attention heads: {config.network.num_heads}\")\n",
    "print(f\"  Constraints enabled: {config.use_constraints}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #     ## Create Model\n",
    "    #\n",
    "    #     Now we instantiate the ProteinPointCloudModel with our configuration.\n",
    "    #     The model will initialize all parameters using the provided RNG keys.\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = ProteinPointCloudModel(config, rngs=rngs)\n",
    "print(f\"\\nCreated model: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #     ## Create Synthetic Dataset\n",
    "    #\n",
    "    #     For this example, we'll create synthetic protein structures with helical geometry.\n",
    "    #     Real protein data would come from the Protein Data Bank (PDB), but synthetic data\n",
    "    #     allows us to run the example without downloading large datasets.\n",
    "    #\n",
    "    #     The synthetic proteins have:\n",
    "    #     - Alpha-helix backbone geometry (common secondary structure)\n",
    "    #     - Only backbone atoms (N, CA, C, O)\n",
    "    #     - Small amounts of Gaussian noise to simulate structural variation\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset\n",
    "data_dir = Path(\"examples_output/protein\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "data_path = data_dir / \"synthetic_proteins.pkl\"\n",
    "\n",
    "# Create dataset with synthetic data if file doesn't exist\n",
    "if not data_path.exists():\n",
    "    print(f\"\\nCreating synthetic protein dataset at {data_path}...\")\n",
    "\n",
    "    # Generate synthetic protein data\n",
    "    num_examples = 10  # Number of protein structures\n",
    "    max_seq_length = 128  # Maximum number of residues\n",
    "    noise_level = 0.1  # Gaussian noise standard deviation\n",
    "    rng = np.random.RandomState(42)\n",
    "\n",
    "    data = []\n",
    "    for i in range(num_examples):\n",
    "        # Create random protein structure with varying length\n",
    "        seq_length = rng.randint(32, max_seq_length + 1)\n",
    "\n",
    "        # Initialize arrays for full atom set (from ATOM_TYPES)\n",
    "        num_atoms = len(ATOM_TYPES)  # Total atom types\n",
    "        atom_positions = np.zeros((seq_length, num_atoms, 3))\n",
    "        atom_mask = np.zeros((seq_length, num_atoms))\n",
    "\n",
    "        # Create alpha-helix backbone geometry\n",
    "        for j in range(seq_length):\n",
    "            # CA positions along a helix (helical rise and rotation)\n",
    "            t = j * 0.5  # Parameter along helix\n",
    "            atom_positions[j, 1, 0] = 3.0 * np.sin(t)  # CA = index 1\n",
    "            atom_positions[j, 1, 1] = 3.0 * np.cos(t)\n",
    "            atom_positions[j, 1, 2] = 1.5 * t  # Rise along z-axis\n",
    "\n",
    "            # N positions relative to CA (N-CA bond length ~ 1.45 Å)\n",
    "            atom_positions[j, 0, :] = atom_positions[j, 1, :] + np.array([-1.45, 0, 0])\n",
    "\n",
    "            # C positions relative to CA (CA-C bond length ~ 1.52 Å)\n",
    "            atom_positions[j, 2, :] = atom_positions[j, 1, :] + np.array([1.52, 0, 0])\n",
    "\n",
    "            # O positions relative to C (C-O bond length ~ 1.23 Å)\n",
    "            atom_positions[j, 4, :] = atom_positions[j, 2, :] + np.array([0, 1.23, 0])\n",
    "\n",
    "            # Set mask to 1 only for backbone atoms\n",
    "            for backbone_idx in BACKBONE_ATOM_INDICES:  # [0, 1, 2, 4]\n",
    "                atom_mask[j, backbone_idx] = 1.0\n",
    "\n",
    "        # Add random noise to backbone atom positions\n",
    "        for backbone_idx in BACKBONE_ATOM_INDICES:\n",
    "            atom_positions[:, backbone_idx, :] += rng.normal(0, noise_level, (seq_length, 3))\n",
    "\n",
    "        # Create residue indices (sequential numbering)\n",
    "        residue_index = np.arange(seq_length)\n",
    "\n",
    "        # Create example dictionary\n",
    "        example = {\n",
    "            \"atom_positions\": atom_positions,\n",
    "            \"atom_mask\": atom_mask,\n",
    "            \"residue_index\": residue_index,\n",
    "        }\n",
    "\n",
    "        data.append(example)\n",
    "\n",
    "    # Save synthetic data\n",
    "    with open(data_path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"  Saved {num_examples} synthetic proteins to {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #     ## Load Dataset\n",
    "    #\n",
    "    #     Now we load the dataset using Artifex's ProteinDataset class.\n",
    "    #     The `backbone_only=True` flag tells the dataset to only return backbone atoms,\n",
    "    #     which matches our model configuration.\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the saved file\n",
    "print(f\"\\nLoading protein dataset from {data_path}...\")\n",
    "dataset = ProteinDataset(data_path, backbone_only=True)\n",
    "print(f\"  Dataset size: {len(dataset)} proteins\")\n",
    "\n",
    "# Get a sample batch\n",
    "batch_indices = list(range(min(4, len(dataset))))\n",
    "batch = dataset.get_batch(batch_indices)\n",
    "\n",
    "print(\"\\nInput batch shapes:\")\n",
    "for key, value in batch.items():\n",
    "    print(f\"  {key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #     ## Model Forward Pass\n",
    "    #\n",
    "    #     Let's run the model on our batch to generate protein structures.\n",
    "    #     The model outputs:\n",
    "    #     - `coordinates`: Predicted 3D positions for each atom\n",
    "    #     - `constraints`: Dictionary with bond length and angle violations (if enabled)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward pass\n",
    "print(\"\\nRunning model forward pass...\")\n",
    "outputs = model(batch)\n",
    "\n",
    "print(\"\\nOutput shapes:\")\n",
    "for key, value in outputs.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  {key}:\")\n",
    "        for subkey, subvalue in value.items():\n",
    "            print(f\"    {subkey}: {subvalue}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #     ## Calculate Loss\n",
    "    #\n",
    "    #     The model's loss function combines:\n",
    "    #     - **Reconstruction loss**: MSE between predicted and target coordinates\n",
    "    #     - **Constraint losses**: Penalties for violating bond lengths and angles\n",
    "    #\n",
    "    #     These losses ensure that the model generates physically plausible structures.\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "print(\"\\nCalculating loss...\")\n",
    "loss_fn = model.get_loss_fn()\n",
    "loss_dict = loss_fn(batch, outputs)\n",
    "\n",
    "print(\"\\nLoss values:\")\n",
    "for key, value in loss_dict.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nExample completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "In this example, you learned:\n",
    "\n",
    "1. **Point Cloud Representation**: How to represent proteins as sets of 3D points\n",
    "   for geometric modeling\n",
    "\n",
    "2. **Model Configuration**: How to configure ProteinPointCloudModel with architecture\n",
    "   and constraint parameters\n",
    "\n",
    "3. **Synthetic Data Generation**: How to create synthetic protein structures with\n",
    "   alpha-helix geometry for testing\n",
    "\n",
    "4. **Geometric Constraints**: How to apply bond length and angle constraints during\n",
    "   generation to ensure chemical validity\n",
    "\n",
    "5. **Model Evaluation**: How to compute reconstruction and constraint losses to\n",
    "   evaluate model performance\n",
    "\n",
    "## Experiments to Try\n",
    "\n",
    "1. **Modify Constraint Weights**: Increase `bond_weight` and `angle_weight` to see\n",
    "   stricter geometric constraints\n",
    "\n",
    "   ```python\n",
    "   config.parameters[\"constraint_config\"] = {\n",
    "       \"bond_weight\": 2.0,  # Increased from 1.0\n",
    "       \"angle_weight\": 1.0,  # Increased from 0.5\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **Larger Proteins**: Increase `max_seq_length` to generate longer protein\n",
    "   structures\n",
    "\n",
    "   ```python\n",
    "   max_seq_length = 256  # Double the size\n",
    "   ```\n",
    "\n",
    "3. **Different Secondary Structures**: Modify the synthetic data generation to create\n",
    "   beta-sheets instead of alpha-helices\n",
    "\n",
    "4. **Add More Atoms**: Modify `num_atoms` to include side-chain atoms beyond the\n",
    "   backbone\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore `protein_model_with_modality.py` to learn about the modality architecture\n",
    "- See `protein_extensions_with_config.py` for advanced protein constraint usage\n",
    "- Check the Artifex documentation for more protein modeling examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
