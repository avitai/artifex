{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Protein-Ligand Co-Design Benchmark Demo\n",
    "\n",
    "**Level:** Advanced | **Runtime:** ~3-5 minutes (CPU), ~1-2 minutes (GPU)\n",
    "**Format:** Python + Jupyter\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example demonstrates a comprehensive protein-ligand co-design benchmark suite,\n",
    "showcasing how to evaluate generative models for drug discovery applications.\n",
    "\n",
    "## Source Code Dependencies\n",
    "\n",
    "**Validated:** 2025-10-15\n",
    "\n",
    "This example depends on the following Artifex source files:\n",
    "- `src/artifex/benchmarks/datasets/crossdocked.py` - CrossDocked2020 dataset\n",
    "- `src/artifex/benchmarks/metrics/protein_ligand.py` - Protein-ligand metrics\n",
    "- `src/artifex/benchmarks/suites/protein_ligand_suite.py` - Benchmark suite\n",
    "- `src/artifex/generative_models/modalities/molecular.py` - Molecular modality\n",
    "\n",
    "**Validation Status:**\n",
    "- ‚úÖ All dependencies validated against `memory-bank/guides/flax-nnx-guide.md`\n",
    "- ‚úÖ No anti-patterns detected (RNG handling, module init, etc.)\n",
    "- ‚úÖ All tests passing for dependency files\n",
    "\n",
    "**Note:** This example was validated as part of Week 0 source dependency validation.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By running this example, you will understand:\n",
    "\n",
    "1. **Molecular Modality Framework** - How to represent and manipulate molecular structures\n",
    "2. **CrossDocked2020 Dataset** - Accessing protein-ligand binding data for benchmarks\n",
    "3. **Protein-Ligand Metrics** - Evaluating binding affinity, molecular validity, and drug-likeness\n",
    "4. **Benchmark Suites** - Running comprehensive evaluations across multiple metrics\n",
    "5. **Model Comparison** - Systematically comparing different model architectures\n",
    "\n",
    "## Key Features Demonstrated\n",
    "\n",
    "- CrossDocked2020 dataset with realistic protein-ligand complexes\n",
    "- Molecular modality framework for chemical structure representation\n",
    "- Binding affinity prediction metrics (RMSE target: <1.0 kcal/mol)\n",
    "- Molecular validity assessment (target: >95% valid structures)\n",
    "- Drug-likeness evaluation using QED score (target: >0.7)\n",
    "- Complete benchmark suite execution with multiple model qualities\n",
    "- Systematic model comparison across performance metrics\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Artifex installed (`source activate.sh`)\n",
    "- Understanding of protein-ligand interactions and drug discovery\n",
    "- Familiarity with molecular representations and binding affinities\n",
    "- Basic knowledge of generative models for molecules\n",
    "\n",
    "## Usage\n",
    "\n",
    "```bash\n",
    "source activate.sh\n",
    "python examples/generative_models/protein/protein_ligand_benchmark_demo.py\n",
    "\n",
    "# Or run the Jupyter notebook for interactive exploration\n",
    "jupyter lab examples/generative_models/protein/protein_ligand_benchmark_demo.ipynb\n",
    "```\n",
    "\n",
    "## Expected Output\n",
    "\n",
    "The example will demonstrate:\n",
    "1. Molecular modality initialization with extensions and adapters\n",
    "2. CrossDocked2020 dataset loading and statistics\n",
    "3. Three protein-ligand specific metrics in action\n",
    "4. Full benchmark suite execution with poor/good/excellent models\n",
    "5. Comparative analysis showing performance improvements\n",
    "\n",
    "**Performance Targets:**\n",
    "- Binding Affinity RMSE: <1.0 kcal/mol\n",
    "- Molecular Validity Rate: >95%\n",
    "- QED (Drug-likeness) Score: >0.7\n",
    "\n",
    "## Estimated Runtime\n",
    "\n",
    "- CPU: ~3-5 minutes\n",
    "- GPU: ~1-2 minutes\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Protein-Ligand Co-Design\n",
    "\n",
    "Protein-ligand co-design involves simultaneously optimizing both the protein binding\n",
    "site and the ligand molecule to achieve strong, specific binding. This is a critical\n",
    "challenge in computational drug discovery.\n",
    "\n",
    "### CrossDocked2020 Dataset\n",
    "\n",
    "A benchmark dataset containing 22.5 million docked protein-ligand pairs from the\n",
    "CrossDock2020 database, with experimentally determined binding affinities and\n",
    "3D structures.\n",
    "\n",
    "### Binding Affinity\n",
    "\n",
    "Binding affinity quantifies how strongly a ligand binds to a protein target, typically\n",
    "measured in kcal/mol. Lower (more negative) values indicate stronger binding.\n",
    "\n",
    "### Molecular Validity\n",
    "\n",
    "Checks whether generated molecular structures satisfy chemical constraints:\n",
    "- Valid bond lengths (1.2-2.0 √Ö for most bonds)\n",
    "- No atomic clashes (atoms too close together)\n",
    "- Chemically feasible atom connectivity\n",
    "\n",
    "### Drug-likeness (QED)\n",
    "\n",
    "Quantitative Estimate of Drug-likeness (QED) scores molecules based on properties\n",
    "like molecular weight, lipophilicity, and structural features that correlate with\n",
    "successful drugs.\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "This demo implements objectives from the generative models benchmark project:\n",
    "1. Molecular modality framework for chemical representations\n",
    "2. CrossDocked2020 dataset integration\n",
    "3. Protein-ligand co-design benchmark with three key metrics\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- **CrossDocked2020 Paper**: \"Improving Protein-Ligand Docking with Deep Learning\"\n",
    "- **Artifex Benchmarks**: `docs/user-guide/benchmarks/protein-ligand.md`\n",
    "- **Molecular Modalities**: `docs/user-guide/modalities/molecular.md`\n",
    "- **Related Examples**:\n",
    "  - `protein_folding_demo.py` - Protein structure prediction\n",
    "  - `geometric_benchmark_demo.py` - Geometric generative models\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "**Issue:** ImportError for molecular modality\n",
    "**Solution:** Ensure Artifex is installed with molecular extras: `uv sync --extra molecular`\n",
    "\n",
    "**Issue:** Dataset loading too slow\n",
    "**Solution:** Reduce `num_samples` parameter in dataset initialization\n",
    "\n",
    "**Issue:** CUDA out of memory\n",
    "**Solution:** Reduce `batch_size` in benchmark configuration\n",
    "\n",
    "## Author\n",
    "\n",
    "Artifex Team\n",
    "\n",
    "## Last Updated\n",
    "\n",
    "2025-10-15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 1: Imports and Setup\n",
    "\n",
    "We import all necessary components for the protein-ligand benchmark:\n",
    "- JAX for numerical operations and automatic differentiation\n",
    "- Flax NNX for neural network components\n",
    "- Artifex benchmark suites, datasets, and metrics\n",
    "- Molecular modality for chemical structure representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "from artifex.benchmarks.datasets.crossdocked import CrossDockedDataset\n",
    "from artifex.benchmarks.metrics.protein_ligand import (\n",
    "    BindingAffinityMetric,\n",
    "    DrugLikenessMetric,\n",
    "    MolecularValidityMetric,\n",
    ")\n",
    "from artifex.benchmarks.suites.protein_ligand_suite import (\n",
    "    ProteinLigandBenchmarkSuite,\n",
    "    ProteinLigandCoDesignBenchmark,\n",
    ")\n",
    "from artifex.generative_models.core.configuration import DataConfig, ModalityConfig\n",
    "from artifex.generative_models.modalities.molecular import MolecularModality\n",
    "\n",
    "\n",
    "# Add the src directory to the path\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 2: Example Protein-Ligand Model\n",
    "\n",
    "This mock model simulates a protein-ligand co-design system for demonstration purposes.\n",
    "In practice, you would replace this with your actual generative model.\n",
    "\n",
    "**Key Features:**\n",
    "- Predicts binding affinities based on structural features\n",
    "- Generates ligands conditioned on protein structure\n",
    "- Supports different quality levels (poor/good/excellent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleProteinLigandModel:\n",
    "    \"\"\"Example protein-ligand co-design model for demonstration.\n",
    "\n",
    "    This mock model simulates a protein-ligand co-design system with:\n",
    "    - Binding affinity prediction\n",
    "    - Ligand generation given protein structure\n",
    "    - Realistic performance characteristics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rngs: nnx.Rngs):\n",
    "        \"\"\"Initialize the example model.\"\"\"\n",
    "        self.rngs = rngs\n",
    "        self.model_quality = \"good\"  # Can be \"poor\", \"good\", or \"excellent\"\n",
    "\n",
    "    def predict_binding_affinity(\n",
    "        self,\n",
    "        protein_coords: jnp.ndarray,\n",
    "        protein_types: jnp.ndarray,\n",
    "        ligand_coords: jnp.ndarray,\n",
    "        ligand_types: jnp.ndarray,\n",
    "        **kwargs,\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Predict binding affinities for protein-ligand complexes.\n",
    "\n",
    "        Args:\n",
    "            protein_coords: Protein coordinates (batch_size, num_protein_atoms, 3)\n",
    "            protein_types: Protein atom types (batch_size, num_protein_atoms)\n",
    "            ligand_coords: Ligand coordinates (batch_size, num_ligand_atoms, 3)\n",
    "            ligand_types: Ligand atom types (batch_size, num_ligand_atoms)\n",
    "\n",
    "        Returns:\n",
    "            Predicted binding affinities (batch_size,) in kcal/mol\n",
    "        \"\"\"\n",
    "        batch_size = protein_coords.shape[0]\n",
    "\n",
    "        # Simulate binding affinity prediction based on structural features\n",
    "        key = jax.random.key(123)\n",
    "        keys = jax.random.split(key, batch_size)\n",
    "\n",
    "        predicted_affinities = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Extract molecular features\n",
    "            protein_center = jnp.mean(protein_coords[i], axis=0)\n",
    "            ligand_center = jnp.mean(ligand_coords[i], axis=0)\n",
    "\n",
    "            # Distance between centers (proxy for binding pocket fit)\n",
    "            center_distance = jnp.linalg.norm(protein_center - ligand_center)\n",
    "\n",
    "            # Number of atoms (proxy for size complementarity)\n",
    "            num_protein_atoms = jnp.sum(protein_types[i] > 0)\n",
    "            num_ligand_atoms = jnp.sum(ligand_types[i] > 0)\n",
    "\n",
    "            # Size ratio (optimal around 0.05-0.1 for ligand/protein)\n",
    "            size_ratio = num_ligand_atoms / (num_protein_atoms + 1e-6)\n",
    "\n",
    "            # Base affinity prediction\n",
    "            base_affinity = -8.0  # Moderate binding\n",
    "\n",
    "            # Adjust based on features\n",
    "            if center_distance < 2.0:  # Close contact is better\n",
    "                base_affinity -= 1.5\n",
    "            elif center_distance > 5.0:  # Too far apart\n",
    "                base_affinity += 2.0\n",
    "\n",
    "            if 0.05 <= size_ratio <= 0.15:  # Good size ratio\n",
    "                base_affinity -= 1.0\n",
    "            elif size_ratio > 0.3:  # Ligand too big\n",
    "                base_affinity += 1.5\n",
    "\n",
    "            # Add noise based on model quality\n",
    "            if self.model_quality == \"excellent\":\n",
    "                noise_scale = 0.3\n",
    "            elif self.model_quality == \"good\":\n",
    "                noise_scale = 0.8\n",
    "            else:  # poor\n",
    "                noise_scale = 2.0\n",
    "\n",
    "            noise = jax.random.normal(keys[i]) * noise_scale\n",
    "            predicted_affinity = base_affinity + noise\n",
    "\n",
    "            predicted_affinities.append(predicted_affinity)\n",
    "\n",
    "        return jnp.array(predicted_affinities)\n",
    "\n",
    "    def generate_ligand(\n",
    "        self,\n",
    "        protein_coords: jnp.ndarray,\n",
    "        protein_types: jnp.ndarray,\n",
    "        num_ligand_atoms: int = 20,\n",
    "        **kwargs,\n",
    "    ) -> dict:\n",
    "        \"\"\"Generate ligands for given protein structures.\n",
    "\n",
    "        Args:\n",
    "            protein_coords: Protein coordinates (batch_size, num_protein_atoms, 3)\n",
    "            protein_types: Protein atom types (batch_size, num_protein_atoms)\n",
    "            num_ligand_atoms: Number of atoms in generated ligands\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with generated ligand coordinates and atom types\n",
    "        \"\"\"\n",
    "        batch_size = protein_coords.shape[0]\n",
    "        key = jax.random.key(456)\n",
    "        keys = jax.random.split(key, batch_size + 1)\n",
    "\n",
    "        generated_coords = []\n",
    "        generated_types = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Find protein center for ligand placement\n",
    "            protein_center = jnp.mean(protein_coords[i], axis=0)\n",
    "\n",
    "            # Generate ligand near protein center (binding pocket)\n",
    "            coord_keys = jax.random.split(keys[i], 2)\n",
    "\n",
    "            # Place ligand center near protein center with some offset\n",
    "            ligand_center_offset = jax.random.normal(coord_keys[0], (3,)) * 1.5\n",
    "            ligand_center = protein_center + ligand_center_offset\n",
    "\n",
    "            # Generate ligand coordinates around this center\n",
    "            ligand_coords = (\n",
    "                jax.random.normal(coord_keys[1], (num_ligand_atoms, 3)) * 1.2\n",
    "                + ligand_center[None, :]\n",
    "            )\n",
    "\n",
    "            # Generate atom types (realistic drug-like distribution)\n",
    "            type_key = keys[-1]\n",
    "            type_probs = jnp.array([0.5, 0.2, 0.15, 0.1, 0.05])  # C, N, O, S, P\n",
    "            ligand_atom_types = jax.random.choice(\n",
    "                type_key, jnp.arange(1, 6), shape=(num_ligand_atoms,), p=type_probs\n",
    "            )\n",
    "\n",
    "            generated_coords.append(ligand_coords)\n",
    "            generated_types.append(ligand_atom_types)\n",
    "\n",
    "        return {\n",
    "            \"coordinates\": jnp.stack(generated_coords),\n",
    "            \"atom_types\": jnp.stack(generated_types),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 3: Molecular Modality Framework Demo\n",
    "\n",
    "The molecular modality provides domain-specific functionality for working with\n",
    "chemical structures, including:\n",
    "- Chemical constraints (bond lengths, angles)\n",
    "- Pharmacophore features (hydrogen bond donors/acceptors, hydrophobic regions)\n",
    "- Adapters for different model types (diffusion, geometric, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_molecular_modality():\n",
    "    \"\"\"Demonstrate the molecular modality framework.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"MOLECULAR MODALITY FRAMEWORK DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    rngs = nnx.Rngs(42)\n",
    "\n",
    "    # Initialize molecular modality\n",
    "    modality = MolecularModality(rngs=rngs)\n",
    "    print(f\"‚úÖ Molecular modality initialized: {modality.name}\")\n",
    "\n",
    "    # Test extensions\n",
    "    config = ModalityConfig(\n",
    "        name=\"molecular_modality_config\",\n",
    "        modality_name=\"molecular\",\n",
    "        metadata={\n",
    "            \"use_chemical_constraints\": True,\n",
    "            \"bond_length_weight\": 1.0,\n",
    "            \"bond_angle_weight\": 0.5,\n",
    "            \"use_pharmacophore_features\": True,\n",
    "            \"pharmacophore_types\": [\"donor\", \"acceptor\", \"hydrophobic\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    extensions = modality.get_extensions(config, rngs=rngs)\n",
    "    print(f\"‚úÖ Extensions loaded: {list(extensions.keys())}\")\n",
    "\n",
    "    # Test adapters\n",
    "    adapters = {\n",
    "        \"diffusion\": modality.get_adapter(\"diffusion\"),\n",
    "        \"geometric\": modality.get_adapter(\"geometric\"),\n",
    "        \"default\": modality.get_adapter(\"default\"),\n",
    "    }\n",
    "    print(f\"‚úÖ Adapters available: {list(adapters.keys())}\")\n",
    "\n",
    "    print(\"üí° Molecular modality framework ready for protein-ligand co-design!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 4: CrossDocked2020 Dataset Demo\n",
    "\n",
    "The CrossDocked2020 dataset contains protein-ligand complexes with:\n",
    "- 3D coordinates for protein and ligand atoms\n",
    "- Atom type information\n",
    "- Binding affinity measurements\n",
    "- Pocket extraction capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_crossdocked_dataset():\n",
    "    \"\"\"Demonstrate the CrossDocked2020 dataset.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CROSSDOCKED2020 DATASET DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    rngs = nnx.Rngs(123)\n",
    "\n",
    "    # Initialize dataset with proper DataConfig\n",
    "    dataset_config = DataConfig(\n",
    "        name=\"crossdocked_demo\",\n",
    "        dataset_name=\"crossdocked\",\n",
    "        metadata={\n",
    "            \"num_samples\": 50,\n",
    "            \"max_protein_atoms\": 200,\n",
    "            \"max_ligand_atoms\": 30,\n",
    "            \"pocket_radius\": 8.0,\n",
    "        },\n",
    "    )\n",
    "    dataset = CrossDockedDataset(\n",
    "        data_path=\"./data/crossdocked\",\n",
    "        config=dataset_config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Dataset initialized with {len(dataset)} samples\")\n",
    "\n",
    "    # Test single sample\n",
    "    sample = dataset[0]\n",
    "    print(\"‚úÖ Sample structure:\")\n",
    "    for key, value in sample.items():\n",
    "        if hasattr(value, \"shape\"):\n",
    "            print(f\"  - {key}: {value.shape} {value.dtype}\")\n",
    "        else:\n",
    "            print(f\"  - {key}: {value}\")\n",
    "\n",
    "    # Test batch generation\n",
    "    batch = dataset.get_batch(batch_size=4, start_idx=10)\n",
    "    print(\"‚úÖ Batch generation:\")\n",
    "    for key, value in batch.items():\n",
    "        if hasattr(value, \"shape\"):\n",
    "            print(f\"  - {key}: {value.shape}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"  - {key}: list of {len(value)} items\")\n",
    "\n",
    "    # Test pocket extraction\n",
    "    sample = dataset[5]\n",
    "    pocket_coords, pocket_indices = dataset.extract_pocket(\n",
    "        sample[\"protein_coords\"], sample[\"ligand_coords\"], radius=6.0\n",
    "    )\n",
    "    print(\n",
    "        f\"‚úÖ Pocket extraction: {len(pocket_coords)}/{len(sample['protein_coords'])} \"\n",
    "        \"atoms in pocket\"\n",
    "    )\n",
    "\n",
    "    # Dataset statistics\n",
    "    stats = dataset.get_statistics()\n",
    "    print(\"‚úÖ Dataset statistics:\")\n",
    "    print(\n",
    "        f\"  - Protein atoms: {stats['protein_atoms']['mean']:.1f} ¬± \"\n",
    "        f\"{stats['protein_atoms']['std']:.1f} \"\n",
    "        f\"(min: {stats['protein_atoms']['min']:.1f}, max: {stats['protein_atoms']['max']:.1f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  - Ligand atoms: {stats['ligand_atoms']['mean']:.1f} ¬± \"\n",
    "        f\"{stats['ligand_atoms']['std']:.1f} \"\n",
    "        f\"(min: {stats['ligand_atoms']['min']:.1f}, max: {stats['ligand_atoms']['max']:.1f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  - Binding affinity: {stats['binding_affinity']['mean']:.1f} ¬± \"\n",
    "        f\"{stats['binding_affinity']['std']:.1f} kcal/mol \"\n",
    "        f\"(min: {stats['binding_affinity']['min']:.1f}, \"\n",
    "        f\"max: {stats['binding_affinity']['max']:.1f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 5: Protein-Ligand Metrics Demo\n",
    "\n",
    "Three specialized metrics evaluate different aspects of protein-ligand modeling:\n",
    "\n",
    "1. **Binding Affinity Metric**: RMSE between predicted and actual binding energies\n",
    "   - Target: <1.0 kcal/mol RMSE\n",
    "   - Also reports Pearson correlation coefficient\n",
    "\n",
    "2. **Molecular Validity Metric**: Chemical plausibility of generated structures\n",
    "   - Target: >95% valid molecules\n",
    "   - Checks bond lengths, angles, and atomic clashes\n",
    "\n",
    "3. **Drug-likeness Metric**: QED score and Lipinski's Rule of Five\n",
    "   - Target: QED >0.7\n",
    "   - Evaluates molecular weight, lipophilicity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_protein_ligand_metrics():\n",
    "    \"\"\"Demonstrate protein-ligand specific metrics.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROTEIN-LIGAND METRICS DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    rngs = nnx.Rngs(456)\n",
    "\n",
    "    # 1. Binding Affinity Metric\n",
    "    print(\"\\n1. Binding Affinity Metric (RMSE target: <1.0 kcal/mol)\")\n",
    "    affinity_metric = BindingAffinityMetric(rngs=rngs)\n",
    "\n",
    "    # Simulate good predictions (should pass target)\n",
    "    true_affinities = jnp.array([-8.2, -6.5, -9.1, -7.8, -5.9])\n",
    "    good_predictions = true_affinities + jax.random.normal(jax.random.key(1), (5,)) * 0.4\n",
    "\n",
    "    good_results = affinity_metric.compute(good_predictions, true_affinities)\n",
    "    print(\n",
    "        f\"   Good model RMSE: {good_results['rmse']:.3f} kcal/mol \"\n",
    "        f\"({'‚úÖ PASS' if good_results['rmse'] < 1.0 else '‚ùå FAIL'})\"\n",
    "    )\n",
    "    print(f\"   Correlation: {good_results['pearson_r']:.3f}\")\n",
    "\n",
    "    # Simulate poor predictions (should fail target)\n",
    "    poor_predictions = true_affinities + jax.random.normal(jax.random.key(2), (5,)) * 1.8\n",
    "    poor_results = affinity_metric.compute(poor_predictions, true_affinities)\n",
    "    print(\n",
    "        f\"   Poor model RMSE: {poor_results['rmse']:.3f} kcal/mol \"\n",
    "        f\"({'‚úÖ PASS' if poor_results['rmse'] < 1.0 else '‚ùå FAIL'})\"\n",
    "    )\n",
    "\n",
    "    # 2. Molecular Validity Metric\n",
    "    print(\"\\n2. Molecular Validity Metric (target: >95%)\")\n",
    "    validity_metric = MolecularValidityMetric(rngs=rngs)\n",
    "\n",
    "    # Generate reasonable molecular structures\n",
    "    batch_size = 8\n",
    "    num_atoms = 20\n",
    "    coordinates = jax.random.normal(rngs.default(), (batch_size, num_atoms, 3)) * 1.5\n",
    "    atom_types = jax.random.randint(rngs.default(), (batch_size, num_atoms), 1, 6)\n",
    "    masks = jnp.ones((batch_size, num_atoms), dtype=jnp.bool_)\n",
    "\n",
    "    validity_results = validity_metric.compute(coordinates, atom_types, masks)\n",
    "    print(\n",
    "        f\"   Validity rate: {validity_results['validity_rate']:.3f} \"\n",
    "        f\"({'‚úÖ PASS' if validity_results['validity_rate'] > 0.95 else '‚ùå FAIL'})\"\n",
    "    )\n",
    "    print(f\"   Bond validity: {validity_results['bond_validity']:.3f}\")\n",
    "    print(f\"   Clash-free: {validity_results['clash_free']:.3f}\")\n",
    "\n",
    "    # 3. Drug-likeness Metric\n",
    "    print(\"\\n3. Drug-likeness Metric (QED target: >0.7)\")\n",
    "    drug_metric = DrugLikenessMetric(rngs=rngs)\n",
    "\n",
    "    # Generate drug-like molecules (moderate size)\n",
    "    drug_coords = jax.random.normal(rngs.default(), (4, 25, 3)) * 2.0\n",
    "    drug_types = jax.random.randint(rngs.default(), (4, 25), 1, 6)\n",
    "    drug_masks = jnp.ones((4, 25), dtype=jnp.bool_)\n",
    "\n",
    "    drug_results = drug_metric.compute(drug_coords, drug_types, drug_masks)\n",
    "    print(\n",
    "        f\"   QED score: {drug_results['qed_score']:.3f} \"\n",
    "        f\"({'‚úÖ PASS' if drug_results['qed_score'] > 0.7 else '‚ùå FAIL'})\"\n",
    "    )\n",
    "    print(f\"   Lipinski compliance: {drug_results['lipinski_compliance']:.3f}\")\n",
    "    print(f\"   Molecular weight: {drug_results['molecular_weight']:.1f} Da\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 6: Complete Benchmark Suite Demo\n",
    "\n",
    "The benchmark suite orchestrates comprehensive evaluation across all metrics.\n",
    "This demo tests three model qualities (poor/good/excellent) to show how\n",
    "performance varies across the target metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_benchmark_suite():\n",
    "    \"\"\"Demonstrate the complete protein-ligand benchmark suite.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROTEIN-LIGAND CO-DESIGN BENCHMARK SUITE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    rngs = nnx.Rngs(789)\n",
    "\n",
    "    # Initialize benchmark suite\n",
    "    suite = ProteinLigandBenchmarkSuite(\n",
    "        dataset_config={\n",
    "            \"num_samples\": 30,  # Small for demo\n",
    "            \"max_protein_atoms\": 150,\n",
    "            \"max_ligand_atoms\": 25,\n",
    "        },\n",
    "        benchmark_config={\n",
    "            \"num_samples\": 16,  # Even smaller for quick demo\n",
    "            \"batch_size\": 4,\n",
    "        },\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Benchmark suite initialized: {suite.name}\")\n",
    "    print(f\"‚úÖ Number of benchmarks: {len(suite.benchmarks)}\")\n",
    "    print(f\"‚úÖ Dataset size: {len(suite.dataset)} samples\")\n",
    "\n",
    "    # Test with different model qualities\n",
    "    model_qualities = [\"poor\", \"good\", \"excellent\"]\n",
    "\n",
    "    for quality in model_qualities:\n",
    "        print(f\"\\n--- Testing {quality.upper()} Model ---\")\n",
    "\n",
    "        model = ExampleProteinLigandModel(rngs)\n",
    "        model.model_quality = quality\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = suite.run_all(model)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"‚è±Ô∏è  Benchmark completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        # Extract key metrics\n",
    "        for benchmark_name, result in results.items():\n",
    "            metrics = result.metrics\n",
    "\n",
    "            rmse = metrics.get(\"binding_affinity_rmse\", 0.0)\n",
    "            validity = metrics.get(\"molecular_validity_rate\", 0.0)\n",
    "            qed = metrics.get(\"qed_score\", 0.0)\n",
    "\n",
    "            print(f\"üìä Results for {quality} model:\")\n",
    "            print(f\"   Binding Affinity RMSE: {rmse:.3f} kcal/mol ({'‚úÖ' if rmse < 1.0 else '‚ùå'})\")\n",
    "            print(f\"   Molecular Validity: {validity:.3f} ({'‚úÖ' if validity > 0.95 else '‚ùå'})\")\n",
    "            print(f\"   QED Score: {qed:.3f} ({'‚úÖ' if qed > 0.7 else '‚ùå'})\")\n",
    "\n",
    "            # Overall assessment\n",
    "            targets_met = sum([rmse < 1.0, validity > 0.95, qed > 0.7])\n",
    "\n",
    "            print(f\"   Overall: {targets_met}/3 targets met\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 7: Model Comparison Demo\n",
    "\n",
    "This section demonstrates how to systematically compare multiple model architectures\n",
    "or configurations using the benchmark suite. The comparison table shows clear\n",
    "differences between baseline, improved, and state-of-the-art models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_model_comparison():\n",
    "    \"\"\"Demonstrate comparing multiple models.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"MODEL COMPARISON DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    rngs = nnx.Rngs(999)\n",
    "\n",
    "    # Create a smaller benchmark for quick comparison\n",
    "    dataset_config = DataConfig(\n",
    "        name=\"crossdocked_comparison\",\n",
    "        dataset_name=\"crossdocked\",\n",
    "        metadata={\n",
    "            \"num_samples\": 20,\n",
    "            \"max_protein_atoms\": 100,\n",
    "            \"max_ligand_atoms\": 20,\n",
    "        },\n",
    "    )\n",
    "    dataset = CrossDockedDataset(\n",
    "        data_path=\"./data/crossdocked\",\n",
    "        config=dataset_config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    benchmark = ProteinLigandCoDesignBenchmark(\n",
    "        dataset=dataset, num_samples=8, batch_size=4, rngs=rngs\n",
    "    )\n",
    "\n",
    "    # Test multiple model configurations\n",
    "    model_configs = [\n",
    "        (\"Baseline Model\", \"poor\"),\n",
    "        (\"Improved Model\", \"good\"),\n",
    "        (\"SOTA Model\", \"excellent\"),\n",
    "    ]\n",
    "\n",
    "    comparison_results = {}\n",
    "\n",
    "    for model_name, quality in model_configs:\n",
    "        model = ExampleProteinLigandModel(rngs)\n",
    "        model.model_quality = quality\n",
    "\n",
    "        result = benchmark.run(model)\n",
    "        comparison_results[model_name] = result.metrics\n",
    "\n",
    "    # Print comparison table\n",
    "    print(\"\\nüìä Model Comparison Results:\")\n",
    "    print(f\"{'Model':<15} {'RMSE':<8} {'Validity':<10} {'QED':<8} {'Status':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    for model_name, metrics in comparison_results.items():\n",
    "        rmse = metrics.get(\"binding_affinity_rmse\", 0.0)\n",
    "        validity = metrics.get(\"molecular_validity_rate\", 0.0)\n",
    "        qed = metrics.get(\"qed_score\", 0.0)\n",
    "\n",
    "        # Check if all targets are met\n",
    "        all_pass = rmse < 1.0 and validity > 0.95 and qed > 0.7\n",
    "        status = \"‚úÖ PASS\" if all_pass else \"‚ùå FAIL\"\n",
    "\n",
    "        print(f\"{model_name:<15} {rmse:<8.3f} {validity:<10.3f} {qed:<8.3f} {status:<10}\")\n",
    "\n",
    "    print(\"\\nTargets: RMSE <1.0 kcal/mol, Validity >95%, QED >0.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Section 8: Main Execution\n",
    "\n",
    "This section orchestrates the complete demonstration, running all components\n",
    "in sequence and providing a summary of the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the complete demonstration.\"\"\"\n",
    "    print(\"üß¨ PROTEIN-LIGAND CO-DESIGN BENCHMARK DEMO\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"This demonstration showcases the implementation of:\")\n",
    "    print(\"‚Ä¢ Molecular Modality Framework\")\n",
    "    print(\"‚Ä¢ CrossDocked2020 Dataset Implementation\")\n",
    "    print(\"‚Ä¢ Protein-Ligand Co-Design Benchmark Suite\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    try:\n",
    "        # Molecular Modality Framework\n",
    "        demonstrate_molecular_modality()\n",
    "\n",
    "        # CrossDocked2020 Dataset\n",
    "        demonstrate_crossdocked_dataset()\n",
    "\n",
    "        # Metrics demonstration\n",
    "        demonstrate_protein_ligand_metrics()\n",
    "\n",
    "        # Complete benchmark suite\n",
    "        demonstrate_benchmark_suite()\n",
    "\n",
    "        # Model comparison\n",
    "        demonstrate_model_comparison()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üéâ IMPLEMENTATION COMPLETE!\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"‚úÖ Molecular modality framework operational\")\n",
    "        print(\"‚úÖ CrossDocked2020 dataset ready\")\n",
    "        print(\"‚úÖ Protein-ligand metrics implemented\")\n",
    "        print(\"‚úÖ Comprehensive benchmark suite functional\")\n",
    "        print(\"\\nüéØ Ready for protein-ligand co-design benchmarks!\")\n",
    "        print(\"üìä Target metrics: RMSE <1.0 kcal/mol, >95% validity, QED >0.7\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during demonstration: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exit(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "- ‚úÖ **Molecular Modality Framework**: Representing chemical structures with\n",
    "  domain-specific extensions\n",
    "- ‚úÖ **CrossDocked2020 Dataset**: Accessing realistic protein-ligand binding data\n",
    "- ‚úÖ **Binding Affinity Prediction**: Evaluating model accuracy with RMSE metrics\n",
    "- ‚úÖ **Molecular Validity**: Ensuring generated molecules satisfy chemical constraints\n",
    "- ‚úÖ **Drug-likeness**: Quantifying pharmaceutical potential with QED scores\n",
    "- ‚úÖ **Benchmark Suites**: Running comprehensive evaluations systematically\n",
    "- ‚úÖ **Model Comparison**: Identifying performance improvements across architectures\n",
    "\n",
    "### Key Performance Targets\n",
    "\n",
    "- **Binding Affinity RMSE**: <1.0 kcal/mol (excellent models achieve ~0.3-0.5)\n",
    "- **Molecular Validity**: >95% (excellent models achieve >98%)\n",
    "- **QED Score**: >0.7 (excellent models achieve >0.8)\n",
    "\n",
    "### Experiments to Try\n",
    "\n",
    "1. **Adjust Model Quality**: Modify the `model_quality` parameter to see how it affects metrics\n",
    "2. **Dataset Size**: Increase `num_samples` to test scalability\n",
    "3. **Batch Size**: Experiment with different `batch_size` values for performance tuning\n",
    "4. **Custom Metrics**: Add your own protein-ligand specific metrics to the suite\n",
    "5. **Real Models**: Replace the mock model with actual generative architectures\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Advanced Protein Modeling**: See `protein_folding_demo.py` for structure prediction\n",
    "- **Geometric Generative Models**: Explore `geometric_benchmark_demo.py` for 3D generation\n",
    "- **Custom Benchmarks**: Create domain-specific benchmark suites for your use case\n",
    "- **Integration**: Combine protein-ligand benchmarks with full training pipelines\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Papers**:\n",
    "  - \"CrossDocked2020: A Dataset for Protein-Ligand Structure Prediction\"\n",
    "  - \"Quantifying the chemical beauty of drugs\" (QED paper)\n",
    "  - \"Lipinski's Rule of Five\"\n",
    "- **Documentation**:\n",
    "  - Artifex Benchmarks: `docs/user-guide/benchmarks/`\n",
    "  - Molecular Modalities: `docs/user-guide/modalities/molecular.md`\n",
    "- **Related Examples**:\n",
    "  - `protein_sequence_generation.py`\n",
    "  - `molecule_generation.py`\n",
    "  - `geometric_models_demo.py`\n",
    "\n",
    "### Troubleshooting Common Issues\n",
    "\n",
    "**Problem:** Slow dataset loading\n",
    "**Solution:** Reduce `num_samples` or `max_protein_atoms` parameters\n",
    "\n",
    "**Problem:** CUDA out of memory\n",
    "**Solution:** Decrease `batch_size` in benchmark configuration\n",
    "\n",
    "**Problem:** Low molecular validity rates\n",
    "**Solution:** Check coordinate scaling and atom type distributions\n",
    "\n",
    "**Problem:** Poor binding affinity predictions\n",
    "**Solution:** Ensure ligand placement near protein center (binding pocket)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed the protein-ligand co-design benchmark demonstration.\n",
    "You now understand how to evaluate generative models for computational drug discovery using\n",
    "Artifex's comprehensive benchmarking framework."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
