{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9172a1c9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Artifex Framework Features Demonstration\n",
    "\n",
    "This example demonstrates the core features of the Artifex framework for generative modeling:\n",
    "\n",
    "- **Unified Configuration System**: Type-safe configuration using frozen dataclasses\n",
    "- **Factory Pattern**: Consistent model creation across all model types\n",
    "- **Composable Loss Functions**: Flexible loss composition with weighted components\n",
    "- **Sampling Methods**: MCMC and SDE sampling for generation\n",
    "- **Modality System**: Domain-specific adapters for images, text, audio, and more\n",
    "\n",
    "**Target Audience**: Users who want to understand the framework's architecture and best practices\n",
    "\n",
    "**Prerequisites**: Basic understanding of generative models and JAX\n",
    "\n",
    "**Runtime**: ~1-2 minutes (CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb4838",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "We'll import the core framework components:\n",
    "- Configuration classes for models, training, data, and optimizers\n",
    "- Loss functions and composition utilities\n",
    "- Sampling methods for generation\n",
    "- Factory functions for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c12ac5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "from artifex.generative_models.core.configuration import (\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainingConfig,\n",
    ")\n",
    "from artifex.generative_models.core.losses import (\n",
    "    CompositeLoss,\n",
    "    mae_loss,\n",
    "    mse_loss,\n",
    "    WeightedLoss,\n",
    ")\n",
    "from artifex.generative_models.core.sampling import mcmc_sampling, sde_sampling\n",
    "from artifex.generative_models.factory import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceca14e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 1. Unified Configuration System\n",
    "\n",
    "Artifex uses a unified configuration system based on frozen dataclasses. This provides:\n",
    "\n",
    "- **Type safety**: Automatic validation of configuration parameters\n",
    "- **Immutability**: Frozen dataclasses prevent accidental mutation\n",
    "- **Serialization**: Easy save/load of configurations via YAML/dict\n",
    "- **Composition**: Configurations can be nested and composed\n",
    "- **JAX-native**: No metaclasses, fully JIT-safe\n",
    "\n",
    "### Why use configurations?\n",
    "\n",
    "- Reproducibility: Save exact hyperparameters\n",
    "- Experimentation: Easy parameter sweeps\n",
    "- Validation: Catch errors before training\n",
    "- Documentation: Self-describing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe00fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_configuration_system():\n",
    "    \"\"\"Demonstrate the unified configuration system.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1. UNIFIED CONFIGURATION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Model configuration\n",
    "    model_config = ModelConfig(\n",
    "        name=\"demo_vae\",\n",
    "        model_class=\"artifex.generative_models.models.vae.VAE\",\n",
    "        input_dim=(28, 28, 1),\n",
    "        hidden_dims=(256, 128),  # Tuple for frozen dataclass\n",
    "        output_dim=32,  # Latent dimension\n",
    "        activation=\"relu\",\n",
    "        dropout_rate=0.1,\n",
    "        parameters={\n",
    "            \"latent_dim\": 32,\n",
    "            \"beta\": 1.0,\n",
    "            \"kl_weight\": 0.5,\n",
    "            \"reconstruction_loss\": \"mse\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"\\nModel Configuration:\")\n",
    "    print(f\"  Name: {model_config.name}\")\n",
    "    print(f\"  Model class: {model_config.model_class}\")\n",
    "    print(f\"  Input dim: {model_config.input_dim}\")\n",
    "    print(f\"  Hidden dims: {model_config.hidden_dims}\")\n",
    "    print(f\"  Parameters: {model_config.parameters}\")\n",
    "\n",
    "    # Optimizer configuration\n",
    "    optimizer_config = OptimizerConfig(\n",
    "        name=\"demo_optimizer\",\n",
    "        optimizer_type=\"adam\",\n",
    "        learning_rate=1e-3,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "\n",
    "    # Training configuration\n",
    "    training_config = TrainingConfig(\n",
    "        name=\"demo_training\",\n",
    "        batch_size=32,\n",
    "        num_epochs=100,\n",
    "        optimizer=optimizer_config,\n",
    "        gradient_clip_norm=1.0,\n",
    "    )\n",
    "\n",
    "    print(\"\\nTraining Configuration:\")\n",
    "    print(f\"  Batch size: {training_config.batch_size}\")\n",
    "    print(f\"  Num epochs: {training_config.num_epochs}\")\n",
    "    print(f\"  Optimizer: {training_config.optimizer.optimizer_type}\")\n",
    "    print(f\"  Learning rate: {training_config.optimizer.learning_rate}\")\n",
    "\n",
    "    # Data configuration\n",
    "    data_config = DataConfig(\n",
    "        name=\"demo_data\",\n",
    "        dataset_name=\"mnist\",\n",
    "        data_dir=\"/tmp/data\",\n",
    "        augmentation=True,\n",
    "        augmentation_params={\"normalize\": True, \"random_flip\": True},\n",
    "    )\n",
    "\n",
    "    print(\"\\nData Configuration:\")\n",
    "    print(f\"  Dataset: {data_config.dataset_name}\")\n",
    "    print(f\"  Augmentation: {data_config.augmentation}\")\n",
    "    print(f\"  Augmentation params: {data_config.augmentation_params}\")\n",
    "\n",
    "    return model_config\n",
    "\n",
    "\n",
    "# Run configuration demonstration\n",
    "model_config = demonstrate_configuration_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0ff00",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 2. Factory Pattern\n",
    "\n",
    "The factory pattern provides a unified interface for creating all model types. Benefits:\n",
    "\n",
    "- **Consistency**: Same creation pattern for VAEs, GANs, diffusion models, etc.\n",
    "- **Flexibility**: Easy to swap model types without changing code\n",
    "- **Validation**: Factory validates compatibility before instantiation\n",
    "- **Extensibility**: Easy to add new model types\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Configuration-driven**: Models are created from configuration objects\n",
    "2. **RNG management**: Proper random number generator handling\n",
    "3. **Type checking**: Factory ensures model types match configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f43ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_factory_pattern(model_config):\n",
    "    \"\"\"Demonstrate the factory pattern for model creation.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. FACTORY PATTERN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Set up RNGs\n",
    "    key = jax.random.key(42)\n",
    "    rngs = nnx.Rngs(params=key, dropout=key)\n",
    "\n",
    "    model = None  # Initialize model variable\n",
    "    try:\n",
    "        # Create model using factory\n",
    "        print(\"\\nCreating model using factory...\")\n",
    "        model = create_model(model_config, rngs=rngs)\n",
    "        print(f\"âœ“ Model created: {type(model).__name__}\")\n",
    "\n",
    "        # Test the model\n",
    "        batch_size = 4\n",
    "        test_input = jax.random.normal(key, (batch_size, *model_config.input_dim))\n",
    "\n",
    "        # VAE forward pass\n",
    "        outputs = model(test_input, rngs=rngs)\n",
    "        print(\"âœ“ Forward pass successful\")\n",
    "        print(f\"  Output keys: {list(outputs.keys())}\")\n",
    "\n",
    "        # Generate samples\n",
    "        if hasattr(model, \"generate\"):\n",
    "            samples = model.generate(num_samples=2, rngs=rngs)\n",
    "            print(\"âœ“ Generation successful\")\n",
    "            print(f\"  Generated shape: {samples.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Factory creation encountered: {e}\")\n",
    "        print(\"This is expected for some model types in the example\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Run factory demonstration\n",
    "model = demonstrate_factory_pattern(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87172de9",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "## 3. Composable Loss System\n",
    "\n",
    "Artifex provides a flexible loss composition system that allows:\n",
    "\n",
    "- **Single losses**: Standard loss functions (MSE, MAE, cross-entropy)\n",
    "- **Weighted losses**: Apply weights to individual loss components\n",
    "- **Composite losses**: Combine multiple losses with different weights\n",
    "- **Component tracking**: Monitor individual loss components during training\n",
    "\n",
    "### Mathematical Formulation:\n",
    "\n",
    "For a composite loss with components L_1, L_2, ..., L_n and weights w_1, w_2, ..., w_n:\n",
    "\n",
    "$$L_{total} = \\\\sum_{i=1}^{n} w_i \\\\cdot L_i(predictions, targets)$$\n",
    "\n",
    "This is essential for multi-objective training in generative models (e.g., VAE with\n",
    "reconstruction + KL loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b957bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_loss_system():\n",
    "    \"\"\"Demonstrate the composable loss system.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. COMPOSABLE LOSS SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create dummy data\n",
    "    key = jax.random.key(42)\n",
    "    predictions = jax.random.normal(key, (8, 32))\n",
    "    targets = jax.random.normal(key, (8, 32))\n",
    "\n",
    "    # Single loss\n",
    "    print(\"\\nSingle loss function:\")\n",
    "    loss_value = mse_loss(predictions, targets)\n",
    "    print(f\"  MSE loss: {loss_value:.4f}\")\n",
    "\n",
    "    # Weighted loss\n",
    "    print(\"\\nWeighted loss:\")\n",
    "    weighted_mse = WeightedLoss(mse_loss, weight=2.0, name=\"weighted_mse\")\n",
    "    weighted_value = weighted_mse(predictions, targets)\n",
    "    print(f\"  Weighted MSE (2x): {weighted_value:.4f}\")\n",
    "\n",
    "    # Composite loss\n",
    "    print(\"\\nComposite loss:\")\n",
    "    composite = CompositeLoss(\n",
    "        [\n",
    "            WeightedLoss(mse_loss, weight=1.0, name=\"reconstruction\"),\n",
    "            WeightedLoss(mae_loss, weight=0.5, name=\"l1_penalty\"),\n",
    "        ],\n",
    "        return_components=True,\n",
    "    )\n",
    "\n",
    "    total_loss, components = composite(predictions, targets)\n",
    "    print(f\"  Total loss: {total_loss:.4f}\")\n",
    "    print(f\"  Components: {components}\")\n",
    "\n",
    "\n",
    "# Run loss system demonstration\n",
    "demonstrate_loss_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecca0ff",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 4. Sampling Methods\n",
    "\n",
    "Artifex provides two main sampling paradigms for generation:\n",
    "\n",
    "### MCMC Sampling\n",
    "\n",
    "Markov Chain Monte Carlo sampling for energy-based models:\n",
    "- Uses Metropolis-Hastings or Langevin dynamics\n",
    "- Samples from arbitrary probability distributions\n",
    "- Requires only a log probability function\n",
    "\n",
    "### SDE Sampling\n",
    "\n",
    "Stochastic Differential Equation sampling for diffusion models:\n",
    "- Solves reverse-time SDEs\n",
    "- Flexible drift and diffusion functions\n",
    "- Used in DDPM, score matching, etc.\n",
    "\n",
    "Both methods are JIT-compiled for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdc4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_sampling_methods():\n",
    "    \"\"\"Demonstrate sampling methods.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"4. SAMPLING METHODS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Define a simple log probability function\n",
    "    def log_prob_fn(x):\n",
    "        # Simple Gaussian\n",
    "        return -0.5 * jnp.sum(x**2)\n",
    "\n",
    "    key = jax.random.key(42)\n",
    "    init_state = jnp.zeros(5)\n",
    "\n",
    "    # MCMC sampling\n",
    "    print(\"\\nMCMC Sampling:\")\n",
    "    mcmc_samples = mcmc_sampling(\n",
    "        log_prob_fn=log_prob_fn,\n",
    "        init_state=init_state,\n",
    "        key=key,\n",
    "        n_samples=100,\n",
    "        n_burnin=50,\n",
    "        step_size=0.1,\n",
    "    )\n",
    "    print(f\"  Samples shape: {mcmc_samples.shape}\")\n",
    "    print(f\"  Mean: {jnp.mean(mcmc_samples, axis=0)}\")\n",
    "    print(f\"  Std: {jnp.std(mcmc_samples, axis=0)}\")\n",
    "\n",
    "    # SDE sampling (for diffusion models)\n",
    "    print(\"\\nSDE Sampling:\")\n",
    "\n",
    "    def drift_fn(x, _t):\n",
    "        return -x  # Simple mean-reverting drift\n",
    "\n",
    "    def diffusion_fn(x, _t):\n",
    "        return jnp.ones_like(x) * 0.1  # Constant diffusion\n",
    "\n",
    "    sde_samples = sde_sampling(\n",
    "        drift_fn=drift_fn,\n",
    "        diffusion_fn=diffusion_fn,\n",
    "        init_state=init_state,\n",
    "        t_span=(0.0, 1.0),\n",
    "        key=key,\n",
    "        n_steps=100,\n",
    "    )\n",
    "    print(f\"  Final sample: {sde_samples}\")\n",
    "\n",
    "\n",
    "# Run sampling demonstration\n",
    "demonstrate_sampling_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74612e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 5. Modality System\n",
    "\n",
    "Artifex's modality system provides domain-specific features for different data types:\n",
    "\n",
    "### Available Modalities:\n",
    "\n",
    "- **Image**: Conv layers, attention, data augmentation\n",
    "- **Text**: Tokenization, embeddings, language-specific metrics\n",
    "- **Audio**: Spectrograms, waveform processing, audio generation\n",
    "- **Protein**: Structure prediction, sequence modeling\n",
    "- **Geometric**: Point clouds, meshes, 3D transformations\n",
    "\n",
    "### Key Benefits:\n",
    "\n",
    "1. **Specialized datasets**: Modality-aware data loading\n",
    "2. **Domain metrics**: FID for images, perplexity for text, etc.\n",
    "3. **Architecture adapters**: Modality-specific network components\n",
    "4. **Pre/post-processing**: Standardized transformations\n",
    "\n",
    "Each modality provides:\n",
    "- `create_dataset()`: Load and preprocess data\n",
    "- `evaluate()`: Compute domain-specific metrics\n",
    "- `get_adapter()`: Get modality-specific model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceecb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_modality_system():\n",
    "    \"\"\"Demonstrate the modality system.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. MODALITY SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Note: The modality system requires specific setup\n",
    "    print(\"\\nAvailable modalities in Artifex:\")\n",
    "    print(\"  - image: Image generation and processing\")\n",
    "    print(\"  - text: Text generation\")\n",
    "    print(\"  - audio: Audio synthesis\")\n",
    "    print(\"  - protein: Protein structure modeling\")\n",
    "    print(\"  - geometric: Point clouds and 3D data\")\n",
    "\n",
    "    # Example of how modalities work\n",
    "    print(\"\\nModality usage pattern:\")\n",
    "    print(\"\"\"\n",
    "    # Get a modality\n",
    "    image_modality = get_modality('image', rngs=rngs)\n",
    "\n",
    "    # Use modality-specific features\n",
    "    dataset = image_modality.create_dataset(config)\n",
    "    metrics = image_modality.evaluate(model, data)\n",
    "\n",
    "    # Apply modality adapter to model\n",
    "    adapter = image_modality.get_adapter('vae')\n",
    "    adapted_model = adapter.adapt(model, config)\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "# Run modality demonstration\n",
    "demonstrate_modality_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024071c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Framework Benefits:\n",
    "\n",
    "1. **Type-safe configurations**: Catch errors before training starts\n",
    "2. **Unified interfaces**: Same patterns across all model types\n",
    "3. **Composable components**: Mix and match losses, samplers, modalities\n",
    "4. **Extensible design**: Easy to add new models and features\n",
    "5. **Production-ready**: Built on JAX for performance and scalability\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Always use `ModelConfig` instead of direct instantiation\n",
    "- Leverage the factory pattern for consistency\n",
    "- Compose losses for multi-objective training\n",
    "- Use appropriate samplers for your model type\n",
    "- Apply modality adapters for domain-specific features\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore specific model examples (VAE, GAN, diffusion)\n",
    "- Implement custom loss functions\n",
    "- Add new modality support\n",
    "- Build custom model architectures using the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7202b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run all demonstrations.\"\"\"\n",
    "    print(\"\\n\" + \"ðŸš€ \" * 20)\n",
    "    print(\"ARTIFEX FRAMEWORK FEATURES DEMONSTRATION\")\n",
    "    print(\"ðŸš€ \" * 20 + \"\\n\")\n",
    "\n",
    "    print(\"This example demonstrates proper usage of Artifex framework features:\")\n",
    "    print(\"- Unified configuration system\")\n",
    "    print(\"- Factory pattern for model creation\")\n",
    "    print(\"- Composable loss functions\")\n",
    "    print(\"- Sampling methods\")\n",
    "    print(\"- Modality system\")\n",
    "\n",
    "    # Run demonstrations\n",
    "    model_config = demonstrate_configuration_system()\n",
    "    demonstrate_factory_pattern(model_config)\n",
    "    demonstrate_loss_system()\n",
    "    demonstrate_sampling_methods()\n",
    "    demonstrate_modality_system()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… Framework features demonstration completed!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\nKey takeaways:\")\n",
    "    print(\"1. Use ModelConfig for all model definitions\")\n",
    "    print(\"2. Use the factory system (create_model) instead of direct instantiation\")\n",
    "    print(\"3. Leverage the composable loss system for complex objectives\")\n",
    "    print(\"4. Use provided sampling methods for generation\")\n",
    "    print(\"5. Apply modality adapters for domain-specific features\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
