{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"Advanced GAN Examples - Showcase Artifex's Advanced GAN Features\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example demonstrates Artifex's advanced GAN implementations on real MNIST data:\n",
    "1. **Conditional GAN**: Class-conditional generation for controlled digit synthesis\n",
    "2. **WGAN-GP**: Wasserstein GAN with gradient penalty for stable training\n",
    "3. **DCGAN**: Deep Convolutional GAN with proven architecture\n",
    "4. **LSGAN**: Least Squares GAN for improved stability\n",
    "\n",
    "All models use Artifex's production-ready implementations with proper training\n",
    "on real MNIST data.\n",
    "\n",
    "## Source Code Dependencies\n",
    "\n",
    "**Validated:** 2025-10-25\n",
    "\n",
    "This example uses Artifex's GAN implementations:\n",
    "- `artifex.generative_models.models.gan.ConditionalGAN` - Conditional GAN\n",
    "- `artifex.generative_models.models.gan.WGAN` - Wasserstein GAN with GP\n",
    "- `artifex.generative_models.models.gan.DCGAN` - Deep Convolutional GAN\n",
    "- `artifex.generative_models.models.gan.LSGAN` - Least Squares GAN\n",
    "\n",
    "**Validation Status:**\n",
    "- ✅ All dependencies use Flax NNX best practices\n",
    "- ✅ Proper RNG handling throughout\n",
    "- ✅ Production-ready implementations from Artifex\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- [x] Using Artifex's ConditionalGAN for label-conditioned generation\n",
    "- [x] Implementing WGAN-GP for stable adversarial training\n",
    "- [x] Training DCGAN with convolutional architecture\n",
    "- [x] Using LSGAN for improved training stability\n",
    "- [x] Training advanced GANs on real MNIST data\n",
    "- [x] Evaluating and visualizing generated samples\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Artifex installed (run `source activate.sh`)\n",
    "- Understanding of standard GANs (see basic gan-mnist tutorial)\n",
    "- Familiarity with JAX and Flax NNX\n",
    "- Knowledge of adversarial training concepts\n",
    "\n",
    "## Usage\n",
    "\n",
    "```bash\n",
    "source activate.sh\n",
    "python examples/generative_models/image/gan/advanced_gan.py\n",
    "```\n",
    "\n",
    "## Expected Output\n",
    "\n",
    "The example will:\n",
    "1. Load real MNIST dataset (60,000 training images)\n",
    "2. Train four advanced GAN variants (Conditional, WGAN-GP, DCGAN, LSGAN)\n",
    "3. Generate samples from each model\n",
    "4. Save visualizations to `examples_output/advanced_gan/`\n",
    "5. Display training metrics and convergence curves\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Conditional GAN\n",
    "\n",
    "Conditional GAN extends standard GAN by conditioning on labels:\n",
    "$$\\\\min_G \\\\max_D V(D, G) = \\\\mathbb{E}_{x,y}[\\\\log D(x|y)] +$$\n",
    "$$\\\\mathbb{E}_{z,y}[\\\\log(1 - D(G(z|y)|y))]$$\n",
    "\n",
    "Where y is the class label.\n",
    "\n",
    "### WGAN-GP\n",
    "\n",
    "Wasserstein GAN with gradient penalty uses Wasserstein distance:\n",
    "$$\\\\mathcal{L}_D = \\\\mathbb{E}[D(G(z))] - \\\\mathbb{E}[D(x)] +$$\n",
    "$$\\\\lambda \\\\mathbb{E}[(\\\\|\\\\nabla_{\\\\hat{x}} D(\\\\hat{x})\\\\|_2 - 1)^2]$$\n",
    "\n",
    "Provides more stable training than standard GAN.\n",
    "\n",
    "### DCGAN\n",
    "\n",
    "Deep Convolutional GAN uses architectural guidelines:\n",
    "- Use strided convolutions instead of pooling\n",
    "- Use batch normalization in both G and D\n",
    "- Remove fully connected hidden layers\n",
    "- Use ReLU in G (except output: tanh)\n",
    "- Use LeakyReLU in D\n",
    "\n",
    "### LSGAN\n",
    "\n",
    "Least Squares GAN uses least squares loss instead of cross-entropy:\n",
    "$$\\\\min_D \\\\mathbb{E}[(D(x) - 1)^2] + \\\\mathbb{E}[D(G(z))^2]$$\n",
    "$$\\\\min_G \\\\mathbb{E}[(D(G(z)) - 1)^2]$$\n",
    "\n",
    "Provides more stable gradients.\n",
    "\n",
    "## Estimated Runtime\n",
    "\n",
    "- **CPU**: ~20-30 minutes total (all 4 variants)\n",
    "- **GPU**: ~5-8 minutes total (if available)\n",
    "\n",
    "## Author\n",
    "\n",
    "Artifex Team\n",
    "\n",
    "## Last Updated\n",
    "\n",
    "2025-10-25\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Advanced GAN Examples\n",
    "\n",
    "This notebook demonstrates Artifex's advanced GAN implementations on real MNIST data.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this example, you will understand:\n",
    "1. How to use Artifex's ConditionalGAN for label-controlled generation\n",
    "2. Using WGAN-GP for stable adversarial training\n",
    "3. Training DCGAN with convolutional architecture\n",
    "4. Using LSGAN for improved stability\n",
    "5. Training and evaluating advanced GAN variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import Dependencies\n",
    "\"\"\"\n",
    "Import Artifex's GAN implementations and utilities for training advanced variants.\n",
    "\"\"\"\n",
    "\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from flax import nnx\n",
    "from tqdm import tqdm\n",
    "\n",
    "from artifex.generative_models.core.configuration.network_configs import (\n",
    "    ConditionalDiscriminatorConfig,\n",
    "    ConditionalGeneratorConfig,\n",
    "    ConditionalParams,\n",
    "    ConvDiscriminatorConfig,\n",
    "    ConvGeneratorConfig,\n",
    ")\n",
    "from artifex.generative_models.core.losses.adversarial import (\n",
    "    least_squares_discriminator_loss,\n",
    "    least_squares_generator_loss,\n",
    "    vanilla_discriminator_loss,\n",
    "    vanilla_generator_loss,\n",
    "    wasserstein_discriminator_loss,\n",
    "    wasserstein_generator_loss,\n",
    ")\n",
    "from artifex.generative_models.core.losses.regularization import gradient_penalty\n",
    "from artifex.generative_models.models.gan import (\n",
    "    ConditionalDiscriminator,\n",
    "    ConditionalGenerator,\n",
    "    DCGANDiscriminator,\n",
    "    DCGANGenerator,\n",
    "    LSGANDiscriminator,\n",
    "    LSGANGenerator,\n",
    "    WGANDiscriminator,\n",
    "    WGANGenerator,\n",
    ")\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR = Path(\"examples_output/advanced_gan\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "Load real MNIST dataset using Hugging Face datasets. This ensures we train on\n",
    "actual handwritten digits with proper training/test splits.\n",
    "\n",
    "**Dataset Properties:**\n",
    "- Training: 60,000 images\n",
    "- Test: 10,000 images\n",
    "- Image size: 28×28×1 (grayscale)\n",
    "- Labels: 0-9 (digit classes)\n",
    "- Values: [-1, 1] (normalized for GAN training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 2: Real MNIST Data Loading with Grain\n",
    "def load_real_mnist(batch_size=128):\n",
    "    \"\"\"Load real MNIST dataset using Grain framework (JAX best practice).\n",
    "\n",
    "    Uses Hugging Face datasets for initial loading, then Grain for efficient\n",
    "    batching and iteration. This follows JAX/Grain best practices for small datasets.\n",
    "\n",
    "    Args:\n",
    "        batch_size: Batch size for training\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_loader, test_loader) as Grain DataLoaders\n",
    "    \"\"\"\n",
    "    import grain.python as grain\n",
    "    from datasets import load_dataset\n",
    "\n",
    "    print(\"\\nLoading MNIST dataset...\")\n",
    "\n",
    "    # Load MNIST from Hugging Face (avoids TensorFlow dependency)\n",
    "    ds = load_dataset(\"mnist\")\n",
    "\n",
    "    # Convert to lists of indices (Grain will fetch data via __getitem__)\n",
    "    class MNISTDataSource(grain.RandomAccessDataSource):\n",
    "        \"\"\"Custom data source for MNIST that handles numpy/JAX arrays.\"\"\"\n",
    "\n",
    "        def __init__(self, hf_dataset):\n",
    "            self.dataset = hf_dataset\n",
    "            # Pre-convert all images to JAX arrays for efficiency\n",
    "            self.images = []\n",
    "            self.labels = []\n",
    "            for item in hf_dataset:\n",
    "                # Convert PIL image to JAX array\n",
    "                image = jnp.array(item[\"image\"], dtype=jnp.float32)\n",
    "                image = image / 255.0  # Normalize to [0, 1]\n",
    "                # Reshape to (H, W, C) format expected by Artifex GANs\n",
    "                image = image[..., jnp.newaxis]  # Add channel: (28, 28, 1)\n",
    "                # Scale to [-1, 1] for GAN training (standard practice)\n",
    "                image = (image - 0.5) * 2.0\n",
    "                self.images.append(image)\n",
    "                self.labels.append(item[\"label\"])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return {\"image\": self.images[index], \"label\": self.labels[index]}\n",
    "\n",
    "    train_source = MNISTDataSource(ds[\"train\"])\n",
    "    test_source = MNISTDataSource(ds[\"test\"])\n",
    "\n",
    "    print(f\"✓ MNIST loaded: {len(train_source)} training images, {len(test_source)} test images\")\n",
    "\n",
    "    # Create samplers\n",
    "    train_sampler = grain.IndexSampler(\n",
    "        num_records=len(train_source),\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        num_epochs=None,  # Infinite epochs\n",
    "    )\n",
    "\n",
    "    test_sampler = grain.IndexSampler(\n",
    "        num_records=len(test_source),\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        num_epochs=1,\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders with batching\n",
    "    train_loader = grain.DataLoader(\n",
    "        data_source=train_source,\n",
    "        sampler=train_sampler,\n",
    "        operations=[grain.Batch(batch_size=batch_size, drop_remainder=True)],\n",
    "        worker_count=0,\n",
    "    )\n",
    "\n",
    "    test_loader = grain.DataLoader(\n",
    "        data_source=test_source,\n",
    "        sampler=test_sampler,\n",
    "        operations=[grain.Batch(batch_size=batch_size, drop_remainder=False)],\n",
    "        worker_count=0,\n",
    "    )\n",
    "\n",
    "    print(f\"✓ Created Grain DataLoaders (batch_size={batch_size})\")\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# Load data once for all examples\n",
    "train_loader, test_loader = load_real_mnist(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Training Infrastructure\n",
    "\n",
    "Common training utilities used by all GAN variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Common Training Infrastructure\n",
    "def train_gan_model(\n",
    "    generator,\n",
    "    discriminator,\n",
    "    train_loader,\n",
    "    model_name: str,\n",
    "    loss_type: str = \"vanilla\",\n",
    "    num_epochs: int = 10,\n",
    "    latent_dim: int = 100,\n",
    "    learning_rate: float = 2e-4,\n",
    "    n_critic: int = 1,\n",
    "    lambda_gp: float = 10.0,\n",
    "):\n",
    "    \"\"\"Train a GAN model using Artifex's loss functions.\n",
    "\n",
    "    This function demonstrates how to use Artifex's modular loss functions\n",
    "    with different GAN architectures. Training steps are JIT-compiled for\n",
    "    performance (following JAX best practices).\n",
    "\n",
    "    Args:\n",
    "        generator: Generator model (Artifex's Generator class)\n",
    "        discriminator: Discriminator model (Artifex's Discriminator class)\n",
    "        train_loader: Training data loader\n",
    "        model_name: Name for logging\n",
    "        loss_type: Loss type ('vanilla', 'wgan', 'lsgan')\n",
    "        num_epochs: Number of training epochs\n",
    "        latent_dim: Latent dimension\n",
    "        learning_rate: Learning rate\n",
    "        n_critic: Number of discriminator updates per generator update\n",
    "        lambda_gp: Gradient penalty coefficient (for WGAN-GP)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (generator, discriminator, metrics_dict)\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"Loss type: {loss_type}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Create optimizers using Artifex's pattern\n",
    "    optimizer_g = nnx.Optimizer(generator, optax.adam(learning_rate, b1=0.5), wrt=nnx.Param)\n",
    "    optimizer_d = nnx.Optimizer(discriminator, optax.adam(learning_rate, b1=0.5), wrt=nnx.Param)\n",
    "\n",
    "    # Determine if models are conditional\n",
    "    is_conditional = isinstance(generator, ConditionalGenerator)\n",
    "\n",
    "    # Define JIT-compiled training steps for better performance\n",
    "    @nnx.jit\n",
    "    def train_discriminator_step(disc, opt_d, real_imgs, fake_imgs, labels_oh=None, seed=0):\n",
    "        \"\"\"JIT-compiled discriminator training step.\"\"\"\n",
    "\n",
    "        def d_loss_fn(disc):\n",
    "            if is_conditional:\n",
    "                real_scores = disc(real_imgs, labels_oh)\n",
    "                fake_scores = disc(fake_imgs, labels_oh)\n",
    "            else:\n",
    "                real_scores = disc(real_imgs)\n",
    "                fake_scores = disc(fake_imgs)\n",
    "\n",
    "            # Use Artifex's loss functions\n",
    "            if loss_type == \"vanilla\":\n",
    "                # Vanilla loss expects probabilities, so apply sigmoid to logits\n",
    "                return vanilla_discriminator_loss(\n",
    "                    nnx.sigmoid(real_scores), nnx.sigmoid(fake_scores)\n",
    "                )\n",
    "            elif loss_type == \"wgan\":\n",
    "                # WGAN loss + gradient penalty (works with raw scores)\n",
    "                w_loss = wasserstein_discriminator_loss(real_scores, fake_scores)\n",
    "                # Compute gradient penalty using Artifex's function\n",
    "                disc_fn = (lambda x: disc(x, labels_oh)) if is_conditional else (lambda x: disc(x))\n",
    "                gp = gradient_penalty(\n",
    "                    real_imgs,\n",
    "                    fake_imgs,\n",
    "                    disc_fn,\n",
    "                    lambda_gp=lambda_gp,\n",
    "                    key=jax.random.key(seed),\n",
    "                )\n",
    "                return w_loss + gp\n",
    "            elif loss_type == \"lsgan\":\n",
    "                # LSGAN works with raw scores\n",
    "                return least_squares_discriminator_loss(real_scores, fake_scores)\n",
    "\n",
    "        # Update discriminator\n",
    "        d_loss, grads = nnx.value_and_grad(d_loss_fn)(disc)\n",
    "        opt_d.update(disc, grads)\n",
    "        return d_loss\n",
    "\n",
    "    @nnx.jit\n",
    "    def train_generator_step(gen, disc, opt_g, z, labels_oh=None):\n",
    "        \"\"\"JIT-compiled generator training step.\"\"\"\n",
    "\n",
    "        def g_loss_fn(gen):\n",
    "            if is_conditional:\n",
    "                fake = gen(z, labels_oh)\n",
    "                fake_scores = disc(fake, labels_oh)\n",
    "            else:\n",
    "                fake = gen(z)\n",
    "                fake_scores = disc(fake)\n",
    "\n",
    "            # Use Artifex's loss functions\n",
    "            if loss_type == \"vanilla\":\n",
    "                return vanilla_generator_loss(nnx.sigmoid(fake_scores))\n",
    "            elif loss_type == \"wgan\":\n",
    "                return wasserstein_generator_loss(fake_scores)\n",
    "            elif loss_type == \"lsgan\":\n",
    "                return least_squares_generator_loss(fake_scores)\n",
    "\n",
    "        # Update generator\n",
    "        g_loss, grads = nnx.value_and_grad(g_loss_fn)(gen)\n",
    "        opt_g.update(gen, grads)\n",
    "        return g_loss\n",
    "\n",
    "    # Training metrics\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "\n",
    "    batches_per_epoch = 468  # 60,000 / 64 ≈ 937, but we'll use 468 for faster training\n",
    "\n",
    "    print(\"Compiling JIT-compiled training steps (first iteration will be slower)...\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_g_loss = 0.0\n",
    "        epoch_d_loss = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        # Set models to training mode\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        # Progress bar for this epoch\n",
    "        pbar = tqdm(\n",
    "            islice(train_loader, batches_per_epoch),\n",
    "            total=batches_per_epoch,\n",
    "            desc=f\"Epoch {epoch + 1}/{num_epochs}\",\n",
    "            leave=True,\n",
    "        )\n",
    "\n",
    "        critic_steps = 0\n",
    "\n",
    "        for batch in pbar:\n",
    "            real_images = batch[\"image\"]\n",
    "            labels = batch.get(\"label\", None)\n",
    "            batch_size = real_images.shape[0]\n",
    "\n",
    "            # Convert images from (H, W, C) to (C, H, W) for Artifex GANs\n",
    "            real_images = jnp.transpose(real_images, (0, 3, 1, 2))\n",
    "\n",
    "            # Generate fake images\n",
    "            seed = epoch * 1000 + batch_count\n",
    "            z = jax.random.normal(jax.random.key(seed), (batch_size, latent_dim))\n",
    "\n",
    "            # Handle conditional vs unconditional generation\n",
    "            labels_onehot = None\n",
    "            if is_conditional:\n",
    "                # Convert labels to one-hot\n",
    "                labels_onehot = jax.nn.one_hot(labels, 10)\n",
    "                fake_images = generator(z, labels_onehot)\n",
    "            else:\n",
    "                fake_images = generator(z)\n",
    "\n",
    "            # Crop WGAN-GP output from 32x32 to 28x28 if needed\n",
    "            if loss_type == \"wgan\" and fake_images.shape[-1] == 32:\n",
    "                # Center crop: 32x32 -> 28x28 (remove 2 pixels from each side)\n",
    "                fake_images = fake_images[:, :, 2:30, 2:30]\n",
    "\n",
    "            # Train discriminator (JIT-compiled)\n",
    "            d_loss = train_discriminator_step(\n",
    "                discriminator, optimizer_d, real_images, fake_images, labels_onehot, seed\n",
    "            )\n",
    "            epoch_d_loss += float(d_loss)\n",
    "\n",
    "            critic_steps += 1\n",
    "\n",
    "            # Train generator every n_critic steps (JIT-compiled)\n",
    "            if critic_steps >= n_critic:\n",
    "                critic_steps = 0\n",
    "\n",
    "                # Generate new latent vectors for generator update\n",
    "                z = jax.random.normal(jax.random.key(seed + 1), (batch_size, latent_dim))\n",
    "\n",
    "                g_loss = train_generator_step(\n",
    "                    generator, discriminator, optimizer_g, z, labels_onehot\n",
    "                )\n",
    "                epoch_g_loss += float(g_loss)\n",
    "\n",
    "            batch_count += 1\n",
    "            pbar.set_postfix(\n",
    "                {\n",
    "                    \"g_loss\": f\"{epoch_g_loss / max(1, batch_count // n_critic):.4f}\",\n",
    "                    \"d_loss\": f\"{epoch_d_loss / batch_count:.4f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Average losses for epoch\n",
    "        avg_g_loss = epoch_g_loss / max(1, batch_count // n_critic)\n",
    "        avg_d_loss = epoch_d_loss / batch_count\n",
    "        g_losses.append(avg_g_loss)\n",
    "        d_losses.append(avg_d_loss)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs} - G Loss: {avg_g_loss:.4f}, D Loss: {avg_d_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Save sample images every 5 epochs to track quality improvement\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            generator.eval()  # Set to eval mode for sampling\n",
    "\n",
    "            # Generate samples for visualization\n",
    "            sample_rngs = nnx.Rngs(999 + epoch)\n",
    "            if is_conditional:\n",
    "                # Generate one sample per class\n",
    "                z_sample = jax.random.normal(sample_rngs.params(), (10, latent_dim))\n",
    "                labels_sample = jax.nn.one_hot(jnp.arange(10), 10)\n",
    "                samples = generator(z_sample, labels_sample)\n",
    "            else:\n",
    "                z_sample = jax.random.normal(sample_rngs.params(), (10, latent_dim))\n",
    "                samples = generator(z_sample)\n",
    "\n",
    "            # Crop WGAN-GP output from 32x32 to 28x28 if needed\n",
    "            if loss_type == \"wgan\" and samples.shape[-1] == 32:\n",
    "                samples = samples[:, :, 2:30, 2:30]\n",
    "\n",
    "            # Convert from (C, H, W) to (H, W, C) and denormalize\n",
    "            samples = jnp.transpose(samples, (0, 2, 3, 1))\n",
    "            samples = (samples + 1) / 2  # [-1, 1] -> [0, 1]\n",
    "\n",
    "            # Save epoch samples\n",
    "            fig, axes = plt.subplots(1, 10, figsize=(15, 2))\n",
    "            for i in range(10):\n",
    "                axes[i].imshow(samples[i, :, :, 0], cmap=\"gray\")\n",
    "                axes[i].axis(\"off\")\n",
    "                if is_conditional:\n",
    "                    axes[i].set_title(f\"{i}\", fontsize=10)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            epoch_dir = OUTPUT_DIR / model_name.lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "            epoch_dir.mkdir(parents=True, exist_ok=True)\n",
    "            plt.savefig(epoch_dir / f\"epoch_{epoch + 1:02d}.png\", dpi=100, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "            generator.train()  # Set back to training mode\n",
    "\n",
    "    # Set to eval mode\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "\n",
    "    print(f\"\\n✓ {model_name} training complete\")\n",
    "    epoch_dir_name = model_name.lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    print(f\"Epoch samples saved to: {OUTPUT_DIR / epoch_dir_name}\")\n",
    "\n",
    "    return generator, discriminator, {\"g_losses\": g_losses, \"d_losses\": d_losses}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Example 1: Conditional GAN\n",
    "\n",
    "Conditional GAN allows generation of specific digit classes by conditioning\n",
    "both generator and discriminator on label information.\n",
    "\n",
    "**Artifex Components:**\n",
    "- `ConditionalGenerator`: Generator with label embedding\n",
    "- `ConditionalDiscriminator`: Discriminator with label conditioning\n",
    "- `ConditionalGAN`: Combined model with conditional loss\n",
    "\n",
    "**Key Features:**\n",
    "- Class-controlled generation\n",
    "- Label consistency in generated samples\n",
    "- Improved training stability through conditioning\n",
    "\n",
    "**Training Notes:**\n",
    "- Uses learning rate of 0.0003 (Keras 2024 best practice)\n",
    "- Trains for 20 epochs (recommended for good convergence)\n",
    "- LeakyReLU with slope 0.2 (standard GAN practice)\n",
    "- Batch size 64 (proven stable for MNIST)\n",
    "- **Loss behavior**: Losses stabilize around G~0.7, D~1.3 after epoch 2\n",
    "  - This is normal! GANs reach Nash equilibrium, not minimize loss\n",
    "  - Fluctuating losses indicate healthy adversarial balance\n",
    "  - Quality improves even when losses stay constant\n",
    "- **Progress tracking**: Samples saved every 5 epochs + epoch 1\n",
    "  - See `examples_output/advanced_gan/conditional_gan/` for progression\n",
    "  - Visual quality improves even when losses plateau\n",
    "- Future improvement: Add label smoothing (0.9/0.1) for enhanced stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create and Train Conditional GAN\n",
    "def create_conditional_gan():\n",
    "    \"\"\"Create Conditional GAN using Artifex's Generator and Discriminator.\"\"\"\n",
    "    rngs = nnx.Rngs(42)\n",
    "\n",
    "    # MNIST is (H, W, C) = (28, 28, 1), but Artifex GANs expect (C, H, W)\n",
    "    output_shape = (1, 28, 28)\n",
    "\n",
    "    # Create conditional params (shared by generator and discriminator)\n",
    "    cond_params = ConditionalParams(\n",
    "        num_classes=10,\n",
    "        embedding_dim=100,  # Standard embedding dimension\n",
    "    )\n",
    "\n",
    "    # Generator config with conditional params\n",
    "    gen_config = ConditionalGeneratorConfig(\n",
    "        name=\"cond_generator\",\n",
    "        output_shape=output_shape,\n",
    "        latent_dim=100,\n",
    "        hidden_dims=(256, 128),  # Smaller for MNIST\n",
    "        batch_norm=True,\n",
    "        activation=\"relu\",\n",
    "        conditional=cond_params,\n",
    "    )\n",
    "\n",
    "    generator = ConditionalGenerator(\n",
    "        config=gen_config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    # Discriminator config with conditional params\n",
    "    disc_config = ConditionalDiscriminatorConfig(\n",
    "        name=\"cond_discriminator\",\n",
    "        input_shape=output_shape,\n",
    "        hidden_dims=(128, 256),\n",
    "        batch_norm=False,  # No batch norm in discriminator\n",
    "        activation=\"leaky_relu\",\n",
    "        conditional=cond_params,\n",
    "    )\n",
    "\n",
    "    discriminator = ConditionalDiscriminator(\n",
    "        config=disc_config,\n",
    "        rngs=nnx.Rngs(43),\n",
    "    )\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "# Create and train using Artifex's loss functions\n",
    "# Following best practices from Keras CGAN tutorial (2024):\n",
    "# - Learning rate: 0.0003 (slightly higher than standard 0.0002)\n",
    "# - Batch size: 64 (already set in data loader)\n",
    "# - Epochs: 20 (increased from 10 for better convergence)\n",
    "# - Latent dim: 100 (standard, could try 128)\n",
    "cond_generator, cond_discriminator = create_conditional_gan()\n",
    "cond_generator, cond_discriminator, cond_metrics = train_gan_model(\n",
    "    cond_generator,\n",
    "    cond_discriminator,\n",
    "    train_loader,\n",
    "    \"Conditional GAN\",\n",
    "    loss_type=\"vanilla\",\n",
    "    num_epochs=20,  # Increased from 10 (Keras recommendation)\n",
    "    learning_rate=3e-4,  # 0.0003 (Keras best practice)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 5: Visualize Conditional GAN Results\n",
    "def visualize_conditional_samples(generator, filename=\"conditional_gan_samples.png\"):\n",
    "    \"\"\"Generate and visualize samples for each digit class.\"\"\"\n",
    "    rngs = nnx.Rngs(123)\n",
    "\n",
    "    # Generate samples for each class\n",
    "    num_classes = 10\n",
    "    samples_per_class = 8\n",
    "\n",
    "    fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(12, 15))\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        z = jax.random.normal(rngs.params(), (samples_per_class, 100))\n",
    "        labels_onehot = jax.nn.one_hot(jnp.ones(samples_per_class, dtype=jnp.int32) * class_id, 10)\n",
    "\n",
    "        # Generate using Artifex's ConditionalGenerator\n",
    "        generated = generator(z, labels_onehot)\n",
    "\n",
    "        # Convert from (C, H, W) to (H, W, C)\n",
    "        generated = jnp.transpose(generated, (0, 2, 3, 1))\n",
    "\n",
    "        for i in range(samples_per_class):\n",
    "            ax = axes[class_id, i]\n",
    "            img = generated[i, :, :, 0]\n",
    "            img = (img + 1) / 2  # Denormalize from [-1,1] to [0,1]\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "            if i == 0:\n",
    "                ax.set_title(f\"Class {class_id}\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / filename, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✓ Saved conditional samples to {OUTPUT_DIR / filename}\")\n",
    "\n",
    "\n",
    "visualize_conditional_samples(cond_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Example 2: WGAN-GP (Wasserstein GAN with Gradient Penalty)\n",
    "\n",
    "WGAN-GP uses Wasserstein distance instead of standard GAN loss, providing\n",
    "more stable training and meaningful loss curves.\n",
    "\n",
    "**Artifex Components:**\n",
    "- `WGANGenerator`: Generator for WGAN\n",
    "- `WGANDiscriminator`: Critic (no sigmoid output)\n",
    "- `WGAN`: Combined model with Wasserstein loss\n",
    "- Artifex's `gradient_penalty`: Enforces Lipschitz constraint\n",
    "\n",
    "**Key Features:**\n",
    "- Wasserstein distance (Earth Mover's Distance)\n",
    "- Gradient penalty for Lipschitz constraint (λ=10)\n",
    "- No sigmoid in discriminator (critic outputs raw scores)\n",
    "- More stable training dynamics\n",
    "- Critic trained 5x per generator update\n",
    "- Meaningful loss metric (Wasserstein distance)\n",
    "\n",
    "**MNIST-Specific Settings (Research-Based):**\n",
    "- Learning rate: 1e-4 (optimal from original paper)\n",
    "- Training epochs: 30+ (WGANs need more epochs than vanilla GANs)\n",
    "- Batch size: 64 (can use up to 512 for better stability)\n",
    "- No BatchNorm in discriminator (incompatible with gradient penalty)\n",
    "- Generator outputs 32x32, center-cropped to 28x28 for MNIST\n",
    "\n",
    "Note: WGAN-GP typically takes longer to converge than vanilla GANs, but\n",
    "provides more stable training with less mode collapse. The Wasserstein\n",
    "loss correlates well with sample quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create and Train WGAN-GP\n",
    "def create_wgan_gp():\n",
    "    \"\"\"Create WGAN-GP using Artifex's components.\n",
    "\n",
    "    Note: WGANGenerator produces 32x32 output (4->8->16->32 upsampling path).\n",
    "    We crop to 28x28 to match MNIST dimensions.\n",
    "    \"\"\"\n",
    "    rngs = nnx.Rngs(45)\n",
    "\n",
    "    # WGANGenerator outputs 32x32, we'll crop to 28x28 for MNIST\n",
    "    generator_output_shape = (1, 32, 32)\n",
    "    mnist_shape = (1, 28, 28)\n",
    "\n",
    "    # WGAN architecture based on original paper and Keras implementation\n",
    "    # Generator: Initial 4x4, then upsample with decreasing channels\n",
    "    # With hidden_dims=(A, B, C): initial 4x4@A, then A->B (4->8), B->C (8->16), C->out (16->32)\n",
    "    # Original paper uses DIM=64: (1024, 512, 256) for generator\n",
    "    gen_config = ConvGeneratorConfig(\n",
    "        name=\"wgan_generator\",\n",
    "        output_shape=generator_output_shape,\n",
    "        latent_dim=100,  # Standard latent dimension (original paper uses 128, but 100 is common)\n",
    "        hidden_dims=(512, 256, 128),  # Larger capacity than before (originally 1024, 512, 256)\n",
    "        batch_norm=True,  # Generator uses BatchNorm\n",
    "        activation=\"relu\",\n",
    "    )\n",
    "\n",
    "    generator = WGANGenerator(\n",
    "        config=gen_config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    # Discriminator: No BatchNorm (incompatible with gradient penalty)\n",
    "    # Progressive downsampling with increasing channels\n",
    "    # Original paper uses: (64, 128, 256) or Keras uses (64, 128, 256, 512)\n",
    "    disc_config = ConvDiscriminatorConfig(\n",
    "        name=\"wgan_discriminator\",\n",
    "        input_shape=mnist_shape,\n",
    "        hidden_dims=(64, 128, 256),  # Standard WGAN-GP progression\n",
    "        batch_norm=False,  # No BatchNorm (incompatible with gradient penalty)\n",
    "        use_instance_norm=True,  # WGAN-GP uses instance norm instead of batch norm\n",
    "        activation=\"leaky_relu\",\n",
    "    )\n",
    "\n",
    "    discriminator = WGANDiscriminator(\n",
    "        config=disc_config,\n",
    "        rngs=nnx.Rngs(46),\n",
    "    )\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "# Create and train using Artifex's WGAN loss + gradient penalty\n",
    "# Based on research from Keras docs, original WGAN-GP paper, and empirical studies (2024)\n",
    "wgan_generator, wgan_discriminator = create_wgan_gp()\n",
    "wgan_generator, wgan_discriminator, wgan_metrics = train_gan_model(\n",
    "    wgan_generator,\n",
    "    wgan_discriminator,\n",
    "    train_loader,\n",
    "    \"WGAN-GP\",\n",
    "    loss_type=\"wgan\",\n",
    "    num_epochs=30,  # WGANs need more epochs (research shows 20-50 minimum)\n",
    "    learning_rate=1e-4,  # Optimal for WGAN-GP on MNIST (original paper setting)\n",
    "    n_critic=5,  # Train critic 5x per generator update (standard WGAN-GP)\n",
    "    lambda_gp=10.0,  # Gradient penalty coefficient (consistent across all sources)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 7: Visualize WGAN-GP Results\n",
    "def visualize_gan_samples(generator, filename, num_samples=64, crop_to_28=False):\n",
    "    \"\"\"Generate and visualize GAN samples.\n",
    "\n",
    "    Args:\n",
    "        generator: The generator model\n",
    "        filename: Output filename for the visualization\n",
    "        num_samples: Number of samples to generate\n",
    "        crop_to_28: If True, crop 32x32 outputs to 28x28 (for WGAN-GP)\n",
    "    \"\"\"\n",
    "    rngs = nnx.Rngs(456)\n",
    "\n",
    "    z = jax.random.normal(rngs.params(), (num_samples, 100))\n",
    "    generated = generator(z)\n",
    "\n",
    "    # Crop WGAN-GP output from 32x32 to 28x28 if needed\n",
    "    if crop_to_28 and generated.shape[-1] == 32:\n",
    "        generated = generated[:, :, 2:30, 2:30]\n",
    "\n",
    "    # Convert from (C, H, W) to (H, W, C)\n",
    "    generated = jnp.transpose(generated, (0, 2, 3, 1))\n",
    "\n",
    "    fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            idx = i * 8 + j\n",
    "            ax = axes[i, j]\n",
    "            img = generated[idx, :, :, 0]\n",
    "            img = (img + 1) / 2  # Denormalize\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / filename, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✓ Saved samples to {OUTPUT_DIR / filename}\")\n",
    "\n",
    "\n",
    "visualize_gan_samples(wgan_generator, \"wgan_gp_samples.png\", crop_to_28=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Example 3: DCGAN (Deep Convolutional GAN)\n",
    "\n",
    "DCGAN introduced architectural guidelines that became standard for GAN training:\n",
    "- Replace pooling with strided convolutions\n",
    "- Use batch normalization in generator\n",
    "- Remove fully connected layers\n",
    "- Use ReLU in generator, LeakyReLU in discriminator\n",
    "\n",
    "**Artifex Components:**\n",
    "- `DCGANGenerator`: Generator with transposed convolutions\n",
    "- `DCGANDiscriminator`: Discriminator with strided convolutions\n",
    "- `DCGAN`: Combined model following DCGAN guidelines\n",
    "\n",
    "**Key Features:**\n",
    "- Proven convolutional architecture\n",
    "- Stable training with batch normalization\n",
    "- Good image quality\n",
    "- Well-established best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 8: Create and Train DCGAN\n",
    "def create_dcgan():\n",
    "    \"\"\"Create DCGAN using Artifex's components.\"\"\"\n",
    "    rngs = nnx.Rngs(48)\n",
    "\n",
    "    output_shape = (1, 28, 28)\n",
    "\n",
    "    gen_config = ConvGeneratorConfig(\n",
    "        name=\"dcgan_generator\",\n",
    "        output_shape=output_shape,\n",
    "        latent_dim=100,\n",
    "        hidden_dims=(256, 128),\n",
    "        batch_norm=True,\n",
    "        activation=\"relu\",\n",
    "    )\n",
    "\n",
    "    generator = DCGANGenerator(\n",
    "        config=gen_config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    disc_config = ConvDiscriminatorConfig(\n",
    "        name=\"dcgan_discriminator\",\n",
    "        input_shape=output_shape,\n",
    "        hidden_dims=(128, 256),\n",
    "        batch_norm=False,\n",
    "        activation=\"leaky_relu\",\n",
    "    )\n",
    "\n",
    "    discriminator = DCGANDiscriminator(\n",
    "        config=disc_config,\n",
    "        rngs=nnx.Rngs(49),\n",
    "    )\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "# Create and train using Artifex's vanilla GAN loss\n",
    "dcgan_generator, dcgan_discriminator = create_dcgan()\n",
    "dcgan_generator, dcgan_discriminator, dcgan_metrics = train_gan_model(\n",
    "    dcgan_generator,\n",
    "    dcgan_discriminator,\n",
    "    train_loader,\n",
    "    \"DCGAN\",\n",
    "    loss_type=\"vanilla\",\n",
    "    num_epochs=10,\n",
    "    learning_rate=2e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 9: Visualize DCGAN Results\n",
    "visualize_gan_samples(dcgan_generator, \"dcgan_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Example 4: LSGAN (Least Squares GAN)\n",
    "\n",
    "LSGAN replaces the cross-entropy loss with a least squares loss, providing\n",
    "more stable gradients during training.\n",
    "\n",
    "**Artifex Components:**\n",
    "- `LSGANGenerator`: Generator optimized for LSGAN\n",
    "- `LSGANDiscriminator`: Discriminator with least squares loss\n",
    "- `LSGAN`: Combined model with LS loss\n",
    "\n",
    "**Key Features:**\n",
    "- Least squares loss instead of cross-entropy\n",
    "- More stable gradients\n",
    "- Better convergence properties\n",
    "- Reduced vanishing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 10: Create and Train LSGAN\n",
    "def create_lsgan():\n",
    "    \"\"\"Create LSGAN using Artifex's components.\"\"\"\n",
    "    rngs = nnx.Rngs(51)\n",
    "\n",
    "    output_shape = (1, 28, 28)\n",
    "\n",
    "    gen_config = ConvGeneratorConfig(\n",
    "        name=\"lsgan_generator\",\n",
    "        output_shape=output_shape,\n",
    "        latent_dim=100,\n",
    "        hidden_dims=(256, 128),\n",
    "        batch_norm=True,\n",
    "        activation=\"relu\",\n",
    "    )\n",
    "\n",
    "    generator = LSGANGenerator(\n",
    "        config=gen_config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    disc_config = ConvDiscriminatorConfig(\n",
    "        name=\"lsgan_discriminator\",\n",
    "        input_shape=output_shape,\n",
    "        hidden_dims=(128, 256),\n",
    "        batch_norm=False,\n",
    "        activation=\"leaky_relu\",\n",
    "    )\n",
    "\n",
    "    discriminator = LSGANDiscriminator(\n",
    "        config=disc_config,\n",
    "        rngs=nnx.Rngs(52),\n",
    "    )\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "# Create and train using Artifex's least squares GAN loss\n",
    "lsgan_generator, lsgan_discriminator = create_lsgan()\n",
    "lsgan_generator, lsgan_discriminator, lsgan_metrics = train_gan_model(\n",
    "    lsgan_generator,\n",
    "    lsgan_discriminator,\n",
    "    train_loader,\n",
    "    \"LSGAN\",\n",
    "    loss_type=\"lsgan\",\n",
    "    num_epochs=10,\n",
    "    learning_rate=2e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 11: Visualize LSGAN Results\n",
    "visualize_gan_samples(lsgan_generator, \"lsgan_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Summary and Comparison\n",
    "\n",
    "Let's compare the training dynamics and results of all four GAN variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 12: Compare All Models\n",
    "def compare_all_models():\n",
    "    \"\"\"Compare training curves and generate comparison grid.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # Plot 1: Conditional GAN losses\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(cond_metrics[\"g_losses\"], label=\"Generator\", linewidth=2)\n",
    "    ax.plot(cond_metrics[\"d_losses\"], label=\"Discriminator\", linewidth=2)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Conditional GAN Training\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: WGAN-GP losses\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(wgan_metrics[\"g_losses\"], label=\"Generator\", linewidth=2)\n",
    "    ax.plot(wgan_metrics[\"d_losses\"], label=\"Critic\", linewidth=2)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"WGAN-GP Training\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: DCGAN losses\n",
    "    ax = axes[1, 0]\n",
    "    ax.plot(dcgan_metrics[\"g_losses\"], label=\"Generator\", linewidth=2)\n",
    "    ax.plot(dcgan_metrics[\"d_losses\"], label=\"Discriminator\", linewidth=2)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"DCGAN Training\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 4: LSGAN losses\n",
    "    ax = axes[1, 1]\n",
    "    ax.plot(lsgan_metrics[\"g_losses\"], label=\"Generator\", linewidth=2)\n",
    "    ax.plot(lsgan_metrics[\"d_losses\"], label=\"Discriminator\", linewidth=2)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"LSGAN Training\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"training_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✓ Saved training comparison to {OUTPUT_DIR}/training_comparison.png\")\n",
    "\n",
    "    # Generate sample comparison grid\n",
    "    rngs = nnx.Rngs(999)\n",
    "    num_samples = 8\n",
    "\n",
    "    fig, axes = plt.subplots(4, num_samples, figsize=(16, 8))\n",
    "\n",
    "    # Conditional GAN - one sample per class\n",
    "    for i in range(num_samples):\n",
    "        z = jax.random.normal(rngs.params(), (1, 100))\n",
    "        label_onehot = jax.nn.one_hot(jnp.array([i]), 10)\n",
    "        img = cond_generator(z, label_onehot)\n",
    "        img = jnp.transpose(img, (0, 2, 3, 1))[0, :, :, 0]\n",
    "        img = (img + 1) / 2\n",
    "        axes[0, i].imshow(img, cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel(\"Conditional\", fontsize=10)\n",
    "        axes[0, i].set_title(f\"{i}\", fontsize=9)\n",
    "\n",
    "    # WGAN-GP\n",
    "    z = jax.random.normal(rngs.params(), (num_samples, 100))\n",
    "    wgan_samples = wgan_generator(z)\n",
    "    wgan_samples = jnp.transpose(wgan_samples, (0, 2, 3, 1))\n",
    "    for i in range(num_samples):\n",
    "        img = wgan_samples[i, :, :, 0]\n",
    "        img = (img + 1) / 2\n",
    "        axes[1, i].imshow(img, cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel(\"WGAN-GP\", fontsize=10)\n",
    "\n",
    "    # DCGAN\n",
    "    z = jax.random.normal(rngs.params(), (num_samples, 100))\n",
    "    dcgan_samples = dcgan_generator(z)\n",
    "    dcgan_samples = jnp.transpose(dcgan_samples, (0, 2, 3, 1))\n",
    "    for i in range(num_samples):\n",
    "        img = dcgan_samples[i, :, :, 0]\n",
    "        img = (img + 1) / 2\n",
    "        axes[2, i].imshow(img, cmap=\"gray\")\n",
    "        axes[2, i].axis(\"off\")\n",
    "        if i == 0:\n",
    "            axes[2, i].set_ylabel(\"DCGAN\", fontsize=10)\n",
    "\n",
    "    # LSGAN\n",
    "    z = jax.random.normal(rngs.params(), (num_samples, 100))\n",
    "    lsgan_samples = lsgan_generator(z)\n",
    "    lsgan_samples = jnp.transpose(lsgan_samples, (0, 2, 3, 1))\n",
    "    for i in range(num_samples):\n",
    "        img = lsgan_samples[i, :, :, 0]\n",
    "        img = (img + 1) / 2\n",
    "        axes[3, i].imshow(img, cmap=\"gray\")\n",
    "        axes[3, i].axis(\"off\")\n",
    "        if i == 0:\n",
    "            axes[3, i].set_ylabel(\"LSGAN\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"model_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✓ Saved model comparison to {OUTPUT_DIR}/model_comparison.png\")\n",
    "\n",
    "\n",
    "compare_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "1. **Conditional GAN**\n",
    "   - Best for: Controlled generation with class labels\n",
    "   - Stability: Moderate (depends on label embedding quality)\n",
    "   - Use Artifex's: `ConditionalGenerator`, `ConditionalDiscriminator`\n",
    "   - Loss: `vanilla_discriminator_loss`, `vanilla_generator_loss`\n",
    "\n",
    "2. **WGAN-GP**\n",
    "   - Best for: Stable training with meaningful metrics\n",
    "   - Stability: Excellent (Wasserstein distance provides stable gradients)\n",
    "   - Use Artifex's: `WGANGenerator`, `WGANDiscriminator`\n",
    "   - Loss: `wasserstein_discriminator_loss`, `wasserstein_generator_loss`, `gradient_penalty`\n",
    "\n",
    "3. **DCGAN**\n",
    "   - Best for: Proven convolutional architecture\n",
    "   - Stability: Good (batch normalization helps)\n",
    "   - Use Artifex's: `DCGANGenerator`, `DCGANDiscriminator`\n",
    "   - Loss: `vanilla_discriminator_loss`, `vanilla_generator_loss`\n",
    "\n",
    "4. **LSGAN**\n",
    "   - Best for: Reduced vanishing gradients\n",
    "   - Stability: Good (least squares loss provides stable gradients)\n",
    "   - Use Artifex's: `LSGANGenerator`, `LSGANDiscriminator`\n",
    "   - Loss: `least_squares_discriminator_loss`, `least_squares_generator_loss`\n",
    "\n",
    "### Artifex Features Demonstrated\n",
    "\n",
    "- **Modular Architecture**: Using Generator and Discriminator classes independently\n",
    "- **Loss Functions**: Leveraging Artifex's adversarial loss library\n",
    "  - `vanilla_*_loss` for standard GAN training\n",
    "  - `wasserstein_*_loss` for WGAN training\n",
    "  - `least_squares_*_loss` for LSGAN training\n",
    "  - `gradient_penalty` for WGAN-GP regularization\n",
    "- **Configurable Components**: Setting hidden dimensions, batch normalization, dropout\n",
    "- **Training Patterns**: Implementing alternating updates with n_critic\n",
    "- **Multi-variant Comparison**: Evaluating different GAN architectures side-by-side\n",
    "\n",
    "### Training Tips\n",
    "\n",
    "- **Conditional GAN**: Use proper label embedding dimensions\n",
    "- **WGAN-GP**: Train critic more frequently (n_critic=5), use lower learning rate\n",
    "- **DCGAN**: Follow architectural guidelines (batch norm, strided convs)\n",
    "- **LSGAN**: Standard GAN training applies, but with better stability\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Try different architectures (hidden dimensions)\n",
    "2. Experiment with hyperparameters (learning rate, batch size)\n",
    "3. Apply to higher-resolution datasets\n",
    "4. Explore other Artifex GAN variants (StyleGAN, CycleGAN)\n",
    "5. Add evaluation metrics (FID, IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Advanced GAN Examples Complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAll visualizations saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - conditional_gan_samples.png\")\n",
    "print(\"  - wgan_gp_samples.png\")\n",
    "print(\"  - dcgan_samples.png\")\n",
    "print(\"  - lsgan_samples.png\")\n",
    "print(\"  - training_comparison.png\")\n",
    "print(\"  - model_comparison.png\")\n",
    "print(\"\\nExperiment with Artifex's other GAN variants!\")\n",
    "print(\"See: artifex.generative_models.models.gan\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
